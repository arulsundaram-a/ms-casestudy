<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Connecting external clients to Red Hat AMQ Broker on Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/n-KevXCaiUc/" /><category term="Event-Driven" /><category term="Java" /><category term="Kubernetes" /><category term="Security" /><category term="Stream Processing" /><category term="ActiveMQ" /><category term="amqp" /><category term="keystore" /><category term="openshift" /><category term="truststore" /><author><name>Paul Vergilis</name></author><id>https://developers.redhat.com/blog/?p=736427</id><updated>2020-08-26T07:00:10Z</updated><published>2020-08-26T07:00:10Z</published><content type="html">&lt;p&gt;Developers deploying &lt;a href="https://developers.redhat.com/products/amq/overview"&gt;Red Hat AMQ&lt;/a&gt; on &lt;a href="https://developers.redhat.com/products/openshift"&gt;Red Hat OpenShift&lt;/a&gt; often wonder how to connect external clients to AMQ Broker using the Transport Layer Security (TLS) protocol, which is an improved successor to the Secure Sockets Layer (SSL) protocol.&lt;/p&gt; &lt;p&gt;In this article, you will learn how to do just that. The steps are as follows:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Generate TLS credentials.&lt;/li&gt; &lt;li&gt;Install the AMQ Broker Operator.&lt;/li&gt; &lt;li&gt;Deploy an AMQ Broker instance.&lt;/li&gt; &lt;li&gt;Define an Advanced Message Queuing Protocol (AMQP) acceptor that uses TLS.&lt;/li&gt; &lt;li&gt;Create an Anycast address.&lt;/li&gt; &lt;li&gt;Connect an external AMQP client and send and receive messages.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;To follow the examples in this article, you will need:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift Container Platform (OCP)&lt;/a&gt; 4.3 or higher.&lt;/li&gt; &lt;li&gt;Cluster admin access for the OCP installation.&lt;/li&gt; &lt;li&gt;Familiarity with &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/cli_reference/openshift_cli/getting-started-cli.html"&gt;&lt;code&gt;oc&lt;/code&gt;, the OpenShift command-line interface (CLI&lt;/a&gt;).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Let&amp;#8217;s get started.&lt;/p&gt; &lt;h2&gt;Part 1: Generating credentials for TLS connections&lt;/h2&gt; &lt;p&gt;In this section, we configure a one-way TLS connection and create and store our TLS credentials.&lt;/p&gt; &lt;h3&gt;One-way TLS&lt;/h3&gt; &lt;p&gt;One-way TLS is the most common way to verify the authenticity of the server that you are accessing and form a secure channel to it. In this authentication mechanism, the content being verified is the authenticity of the server itself. The client is never verified.&lt;/p&gt; &lt;h3&gt;Storing TLS credentials&lt;/h3&gt; &lt;p&gt;When deploying AMQ broker(s) to OpenShift, any defined connectors that are secured via TLS must store the TLS credentials. You can use any of the following secret mechanisms to store the credentials:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A &lt;code&gt;broker.ks&lt;/code&gt;, which must be a Base64-encoded keystore.&lt;/li&gt; &lt;li&gt;A &lt;code&gt;client.ts&lt;/code&gt;, which must be a Base64-encoded truststore.&lt;/li&gt; &lt;li&gt;A &lt;code&gt;keyStorePassword&lt;/code&gt;, which must be specified in raw text.&lt;/li&gt; &lt;li&gt;A &lt;code&gt;trustStorePasswordspecified&lt;/code&gt;, which must be specified in raw text.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For TLS connections, AMQ requires a broker keystore, a client keystore, and a client truststore that includes the broker keystore. In the next section, we will create a broker keystore, export the broker certificate, create a client truststore, import the broker certificate into the client truststore, and then create a broker truststore.&lt;/p&gt; &lt;h3&gt;Step 1: Create the broker keystore&lt;/h3&gt; &lt;p&gt;Note that I&amp;#8217;m using the &lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/javase/7/docs/technotes/tools/windows/keytool.html"&gt;Java Keytool&lt;/a&gt; to generate the necessary certificates and stores for this example. First, generate a self-signed certificate for the broker keystore. When asked for a password, use &lt;code&gt;password&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ keytool -genkey -alias broker -keyalg RSA -keystore broker.ks&lt;/pre&gt; &lt;p&gt;Next, export the certificate so that it can be shared with clients:&lt;/p&gt; &lt;pre&gt;$ keytool -export -alias broker -keystore broker.ks -file broker_cert&lt;/pre&gt; &lt;p&gt;Create a client truststore that imports the broker certificate:&lt;/p&gt; &lt;pre&gt;$ keytool -import -alias broker -keystore client.ts -file broker_cert&lt;/pre&gt; &lt;p&gt;Generate a self-signed certificate for the broker trust store:&lt;/p&gt; &lt;pre&gt;$ keytool -genkey -alias broker -keyalg RSA -keystore broker.ts&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: When you import the &lt;code&gt;broker_cert&lt;/code&gt; make sure that you specify &lt;code&gt;yes&lt;/code&gt; to the dialog: &lt;code&gt;Trust this certificate? [no]:  yes&lt;/code&gt;. The default setting is &lt;code&gt;no&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Step 2: Create the secret name&lt;/h3&gt; &lt;p&gt;In this example, we create the secret &lt;i&gt;after&lt;/i&gt; generating the certificates and stores. By default, the secret name has the following format:&lt;/p&gt; &lt;pre&gt;&amp;#60;CustomResourceName&amp;#62;-&amp;#60;AcceptorName&amp;#62;-secret&lt;/pre&gt; &lt;p&gt;Following this format, I have named this secret &lt;code&gt;ex-aao-amqp-secret&lt;/code&gt;. You can use whatever naming format you like. We will provide this secret name in the custom resource for ActiveMQ Artemis, which we&amp;#8217;ll use to deploy the broker shortly.&lt;/p&gt; &lt;h2&gt;Part 2: Configuring OpenShift&lt;/h2&gt; &lt;p&gt;Next, we log into our OpenShift cluster as a system admin, create a project named &lt;code&gt;amq-broker-ssl&lt;/code&gt;, and create a secret for the project (in my case, &lt;code&gt;ex-aao-amqp-secret&lt;/code&gt;). Note that I&amp;#8217;m using OpenShift 4.4 for this example.&lt;/p&gt; &lt;h3&gt;Step 1: Create the project and secret&lt;/h3&gt; &lt;p&gt;Log into OpenShift by entering the command:&lt;/p&gt; &lt;pre&gt;$ oc login &amp;#60;CLUSTER_API_URL&amp;#62;&lt;/pre&gt; &lt;p&gt;Create a new project:&lt;/p&gt; &lt;pre&gt;$ oc new-project amq-broker-ssl&lt;/pre&gt; &lt;p&gt;Create the secret:&lt;/p&gt; &lt;pre&gt;$ oc create secret generic ex-aao-amqp-secret \ --from-file=broker.ks \ --from-literal=keyStorePassword=password \ --from-file=client.ts=broker.ts \ --from-literal=trustStorePassword=password &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: In the snippet&lt;code&gt;--from-file=client.ts=broker.ts&lt;/code&gt;, we provide the &lt;code&gt;broker.ts&lt;/code&gt;, which is correct. However, we&amp;#8217;re aliasing it in the secret as &lt;code&gt;client.ts&lt;/code&gt;. The alias is the value that the broker image looks for in the secret.&lt;/p&gt; &lt;h3&gt;Step 2: Open the project in OpenShift&lt;/h3&gt; &lt;p&gt;Next, log in to the OpenShift console and click on &lt;b&gt;Projects&lt;/b&gt;. As shown in Figure 1, you&amp;#8217;ll see the project that we&amp;#8217;ve just created.&lt;/p&gt; &lt;div id="attachment_767667" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig1-1.png"&gt;&lt;img aria-describedby="caption-attachment-767667" class="wp-image-767667 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig1-1-1024x326.png" alt="The amq-broker-ssl project highlighted in the OpenShift console's Projects screen." width="640" height="204" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig1-1-1024x326.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig1-1-300x95.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig1-1-768x244.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-767667" class="wp-caption-text"&gt;Figure 1: Find and click your new project in the OpenShift console&amp;#8217;s Projects screen.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 2 shows the project details.&lt;/p&gt; &lt;div id="attachment_767677" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767677" class="wp-image-767677 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig2-1024x742.png" alt="Details of the amq-broker-ssl project with &amp;#34;10 Secrets&amp;#34; highlighted" width="640" height="464" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig2-1024x742.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig2-300x217.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig2-768x557.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig2.png 1581w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767677" class="wp-caption-text"&gt;Figure 2: Click the project&amp;#8217;s secrets to view them.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Click &lt;b&gt;Secrets&lt;/b&gt; in the &lt;b&gt;Inventory&lt;/b&gt; panel shown in Figure 2. Find the &lt;code&gt;ex-aao-amqp-secret&lt;/code&gt;, which appears in the list of secrets shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_767687" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767687" class="wp-image-767687 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig3-1024x601.png" alt="A list of secrets for the amq-broker-ssl project with ex-aao-amqp-secret highlighted" width="640" height="376" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig3-1024x601.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig3-300x176.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig3-768x451.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig3.png 1311w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767687" class="wp-caption-text"&gt;Figure 3: Click the secret to view details.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you drill into &lt;code&gt;ex-aao-amqp-secret&lt;/code&gt;, as shown in Figure 4, you&amp;#8217;ll see &lt;code&gt;broker.ks&lt;/code&gt;, &lt;code&gt;client.ts&lt;/code&gt;, and their respective passwords, which we supplied when we created the secret.&lt;/p&gt; &lt;div id="attachment_767697" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767697" class="wp-image-767697 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig4-1024x924.png" alt="ex-aao-amqp-secret details screen " width="640" height="578" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig4-1024x924.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig4-300x271.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig4-768x693.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig4.png 1309w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767697" class="wp-caption-text"&gt;Figure 4: View secret details to verify broker.ks, client.ts, keyStorePassword and trustStorePasswords were added.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We’ve created our TLS credentials and stored them in a namespace secret. Next, let&amp;#8217;s install AMQ Broker.&lt;/p&gt; &lt;h2&gt;Part 3: Installing AMQ&lt;/h2&gt; &lt;p&gt;In this section, we install the AMQ Broker Operator from the OperatorHub into our OpenShift cluster. To install the Operator, you must have cluster-admin privileges for the OpenShift cluster.&lt;/p&gt; &lt;p&gt;Before we install AMQ Broker, let&amp;#8217;s first look at what it is.  Below is a brief overview, if you would like to learn more about AMQ Broker and other AMQ offerings, go to &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.7/html/introducing_red_hat_amq_7/index"&gt;Red Hat AMQ 7&lt;/a&gt;&lt;/p&gt; &lt;p&gt;AMQ Broker is a high-performance messaging implementation based on ActiveMQ Artemis. It uses an asynchronous journal for fast message persistence and supports multiple languages, protocols, and platforms.&lt;/p&gt; &lt;p&gt;Red Hat AMQ Broker 7.7 (the latest version as of this article) is available as a containerized image that is provided for use with OpenShift Container Platform (OCP) 3.11 and later.&lt;/p&gt; &lt;p&gt;AMQ Broker on OCP provides similar functionality to Red Hat AMQ Broker, but some aspects of the functionality need to be configured specifically for use with OpenShift Container Platform.&lt;/p&gt; &lt;h3&gt;Install the AMQ Broker Operator&lt;/h3&gt; &lt;p&gt;Log in to the web console as a cluster admin. On the left-side navigation bar, expand &lt;b&gt;Operators&lt;/b&gt; and click on &lt;b&gt;OperatorHub&lt;/b&gt;. In the search field, type &lt;b&gt;AMQ&lt;/b&gt;, and select the &lt;b&gt;Red Hat Integration – AMQ Broker&lt;/b&gt; tile, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_767717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767717" class="wp-image-767717 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig5-1024x746.png" alt="OpenShift OperatorHub with Red Hat Integration - AMQ Broker highlighted" width="640" height="466" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig5-1024x746.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig5-300x219.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig5-768x560.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig5.png 1269w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767717" class="wp-caption-text"&gt;Figure 5: Find and click the Operator in the OpenShift OperatorHub.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;On the installation screen, click the &lt;b&gt;Install&lt;/b&gt; button, as shown in Figure 6.&lt;/p&gt; &lt;div id="attachment_767757" style="width: 565px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767757" class="wp-image-767757" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig6-1.png" alt="The Red Hat Integration - AMQ Broker screen with the Install button highlighted" width="555" height="617" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig6-1.png 905w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig6-1-270x300.png 270w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig6-1-768x854.png 768w" sizes="(max-width: 555px) 100vw, 555px" /&gt;&lt;p id="caption-attachment-767757" class="wp-caption-text"&gt;Figure 6: Click Install to install the Operator.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Be sure to select a specific namespace on the cluster and keep the defaults for the &lt;b&gt;Update channel&lt;/b&gt; and &lt;b&gt;Approval strategy&lt;/b&gt;. Select &lt;code&gt;amq-broker-ssl&lt;/code&gt; under &lt;b&gt;Installed Namespace*&lt;/b&gt;, as shown in Figure 7.&lt;/p&gt; &lt;div id="attachment_767747" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767747" class="wp-image-767747 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig7-1024x760.png" alt="The Install Operator dialog box with &amp;#34;A specific namespace on the cluster&amp;#34; highlighted" width="640" height="475" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig7-1024x760.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig7-300x223.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig7-768x570.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig7.png 1192w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767747" class="wp-caption-text"&gt;Figure 7: Select your specific namespace and then click install to add the AMQ Broker Operator.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Wait a few minutes for the Operator to install. Once it has successfully installed, you should see the status change to &lt;b&gt;Succeeded&lt;/b&gt;, as shown in Figure 8.&lt;/p&gt; &lt;div id="attachment_767777" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig8.png"&gt;&lt;img aria-describedby="caption-attachment-767777" class="wp-image-767777 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig8-1024x334.png" alt="The Installed Operators screen with &amp;#34;Succeeded&amp;#34; highlighted." width="640" height="209" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig8-1024x334.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig8-300x98.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig8-768x251.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig8.png 1283w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-767777" class="wp-caption-text"&gt;Figure 8: Verify that AMQ Broker Operator is successfully installed.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Part 4: Deploying the AMQ Broker&lt;/h2&gt; &lt;p&gt;Next, we will deploy a broker with a defined &lt;a target="_blank" rel="nofollow" href="https://www.amqp.org"&gt;AMQP&lt;/a&gt; connector secured with TLS.&lt;/p&gt; &lt;h3&gt;Step 1: Create the AMQ Broker instance&lt;/h3&gt; &lt;p&gt;While on the &lt;b&gt;Installed Operators&lt;/b&gt; page, click the &lt;b&gt;Red Hat Integration &amp;#8211; AMQ Broker&lt;/b&gt; link to see the Operator details shown in Figure 9.&lt;/p&gt; &lt;div id="attachment_767787" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig9.png"&gt;&lt;img aria-describedby="caption-attachment-767787" class="wp-image-767787 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig9-1024x332.png" alt="The Installed Operators screen with Red Hat Integration - AMQ Broker highlighted." width="640" height="208" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig9-1024x332.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig9-300x97.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig9-768x249.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig9.png 1290w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-767787" class="wp-caption-text"&gt;Figure 9: Click the Operator&amp;#8217;s name to view its details.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In the Operator details, you&amp;#8217;ll see tiles for each of the Operator APIs. Click on the &lt;b&gt;Create Instance&lt;/b&gt; link inside the &lt;b&gt;AMQ Broker&lt;/b&gt; tile, as shown in Figure 10.&lt;/p&gt; &lt;div id="attachment_767797" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767797" class="wp-image-767797 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig10-1024x649.png" alt="The Operator Details page for the AMQ Broker Operator with AMQ Broker highlighted." width="640" height="406" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig10-1024x649.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig10-300x190.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig10-768x487.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig10.png 1302w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767797" class="wp-caption-text"&gt;Figure 10: Find the Operator API you want to use and click Create Instance beneath it.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Step 2: Create the ActiveMQ Artemis instance&lt;/h3&gt; &lt;p&gt;Now, copy and paste the &lt;b&gt;ActiveMQArtemis&lt;/b&gt; custom resource below into the &lt;b&gt;Create ActiveMQArtemis&lt;/b&gt; YAML editor. Notice the acceptors stanza in the YAML file, where we define the AMQP acceptor:&lt;/p&gt; &lt;pre&gt;apiVersion: broker.amq.io/v2alpha2 kind: ActiveMQArtemis metadata: name: ex-aao spec: deploymentPlan: size: 1 image: registry.redhat.io/amq7/amq-broker:7.6 requireLogin: false adminUser: admin adminPassword: admin console: expose: true acceptors: - name: amqp protocols: amqp port: 5672 sslEnabled: true sslSecret: ex-aao-amqp-secret verifyHost: false expose: true &lt;/pre&gt; &lt;p&gt;Also, note that I set &lt;code&gt;sslEnabled: true&lt;/code&gt;. When you set &lt;code&gt;sslEnabled: true&lt;/code&gt; for an acceptor, you&amp;#8217;ll need to specify the named secret that contains the keys &lt;code&gt;broker.ks&lt;/code&gt;,  &lt;code&gt;client.ts&lt;/code&gt;,  &lt;code&gt;keyStorePassword&lt;/code&gt;,  and &lt;code&gt;trustStorePassword&lt;/code&gt;. The broker image will look for these in the named secret. If they&amp;#8217;re not present, OpenShift will fail to schedule the broker pod until it finds them.&lt;/p&gt; &lt;p&gt;As shown in Figure 11, I specified the name of the secret as &lt;code&gt;sslSecret: ex-aao-amqp-secret&lt;/code&gt;.&lt;/p&gt; &lt;div id="attachment_767817" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767817" class="wp-image-767817 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig11-1-1024x926.png" alt="The Create ActiveMQArtemis screen" width="640" height="579" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig11-1-1024x926.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig11-1-300x271.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig11-1-768x695.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig11-1.png 1300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767817" class="wp-caption-text"&gt;Figure 11: Create the ActiveMQ Artemis instance.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When you are done editing the file, click &lt;b&gt;Create&lt;/b&gt;. You&amp;#8217;ll see an instance of the broker that we just created. Click on the &lt;b&gt;ex-aao&lt;/b&gt; link to see the &lt;b&gt;AMQ Broker Overview&lt;/b&gt; that is shown in Figure 12.&lt;/p&gt; &lt;div id="attachment_767827" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767827" class="wp-image-767827 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig12-1024x427.png" alt="The ActiveMQArtemis Operator Details screen with ex-aao highlighted" width="640" height="267" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig12-1024x427.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig12-300x125.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig12-768x321.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig12.png 1313w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767827" class="wp-caption-text"&gt;Figure 12: Click the new broker instance in the ActiveMQArtemis Operator Details screen.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As shown in Figure 13, the pod status indicates that one pod is ready.&lt;/p&gt; &lt;div id="attachment_767847" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig13.png"&gt;&lt;img aria-describedby="caption-attachment-767847" class="wp-image-767847" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig13.png" alt="The AMQ Broker Overview screen showing that the new pod is ready." width="640" height="528" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig13.png 971w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig13-300x247.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig13-768x634.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-767847" class="wp-caption-text"&gt;Figure 13: View the status of your new pod in the AMQ Broker Overview screen.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Step 3: Create the AMQ Broker address&lt;/h3&gt; &lt;p&gt;Next, we&amp;#8217;ll define our address &lt;code&gt;test.foo&lt;/code&gt;, from which our client applications will send and receive messages. Click on &lt;b&gt;Installed Operators&lt;/b&gt; under &lt;b&gt;Operators&lt;/b&gt; in the left-hand navigation panel and drill into the &lt;b&gt;Red Hat Integration &amp;#8211; AMQ Broker&lt;/b&gt;. Then, click the &lt;b&gt;Create Instance&lt;/b&gt; link in the &lt;b&gt;AMQ Broker Address&lt;/b&gt; tile, as shown in Figure 14.&lt;/p&gt; &lt;div id="attachment_767887" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767887" class="wp-image-767887 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig14-1024x758.png" alt="The Red Hat Integration - AMQ Broker installed Operators details page with the Create Instance link under ActiveMQ Artemis Address highlighted" width="640" height="474" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig14-1024x758.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig14-300x222.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig14-768x568.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig14.png 1220w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767887" class="wp-caption-text"&gt;Figure 14: Click Create Instance to view the configuration before proceeding.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Copy and paste the following YAML for the &lt;b&gt;ActiveMQArtemisAddress&lt;/b&gt; custom resource into the YAML editor:&lt;/p&gt; &lt;pre&gt;apiVersion: broker.amq.io/v2alpha1 kind: ActiveMQArtemisAddress metadata: name: ex-aao-address-test-foo spec: addressName: test.foo queueName: test.foo routingType: anycast &lt;/pre&gt; &lt;p&gt;Click &lt;b&gt;Create&lt;/b&gt; when you are done, as shown in Figure 15.&lt;/p&gt; &lt;div id="attachment_767897" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-767897" class="wp-image-767897 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig15-1024x924.png" alt="Create ActiveMQArtemisAddress screen" width="640" height="578" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig15-1024x924.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig15-300x271.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig15-768x693.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig15.png 1312w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-767897" class="wp-caption-text"&gt;Figure 15: Create your ActiveMQArtemisAddress instance.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We&amp;#8217;ve created an address named &lt;code&gt;test.foo&lt;/code&gt; on the running broker pod which will create a point-to-point message queue. Next, we&amp;#8217;ll test the ability to send and receive messages.&lt;/p&gt; &lt;h2&gt;Part 5: Sending and receiving messages&lt;/h2&gt; &lt;p&gt;For this part of the example, I am using the out-of-the-box ActiveMQ Artemis CLI client to send and receive messages. The CLI client comes bundled in the &lt;a target="_blank" rel="nofollow" href="https://activemq.apache.org/components/artemis/download/"&gt;Apache ActiveMQ Artemis distribution&lt;/a&gt;. Once you&amp;#8217;ve downloaded the distribution and unzipped or un-tarred it to a directory, you&amp;#8217;ll find the &lt;code&gt;artemis&lt;/code&gt; executable in the &lt;code&gt;bin&lt;/code&gt; directory. From there, you can run the commands in the following steps.&lt;/p&gt; &lt;h3&gt;Step 1: Produce messages&lt;/h3&gt; &lt;p&gt;Send 10 messages to &lt;code&gt;test.foo&lt;/code&gt; using the following command (change the URL and location of the truststore if yours is different from the one in my example).  If you recall, in the &lt;b&gt;ActiveMQArtemis&lt;/b&gt; custom resource where we defined our protocol as &lt;code&gt;amqp&lt;/code&gt;, we set &lt;code&gt;expose: true&lt;/code&gt;, which created a service and route. The URL I&amp;#8217;m using is derived from the location specified in the &lt;code&gt;ex-aao-amqp-0-svc-rte&lt;/code&gt; route, replacing the &lt;code&gt;https&lt;/code&gt; with &lt;code&gt;amqps&lt;/code&gt; and adding port 443:&lt;/p&gt; &lt;pre&gt;$ ./bin/artemis producer --url 'amqps://ex-aao-amqp-0-svc-rte-amq-broker-ssl.apps.ocp42.lab.example:443?jms.username=admin&amp;#38;jms.password=admin&amp;#38;transport.trustStoreLocation=/opt/playground/amq76-ocp-deploy/client.ts&amp;#38;transport.trustStorePassword=password&amp;#38;transport.verifyHost=false' --threads 1 --protocol amqp --message-count 10 --destination 'queue://test.foo' Producer ActiveMQQueue[test.foo], thread=0 Produced: 10 messages Producer ActiveMQQueue[test.foo], thread=0 Elapsed time in second : 0 s Producer ActiveMQQueue[test.foo], thread=0 Elapsed time in milli second : 192 milli seconds &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: You&amp;#8217;ll need to change the URL and location of &lt;code&gt;client.ts&lt;/code&gt;. If you used a different password, change that too.&lt;/p&gt; &lt;h3&gt;Step 2: View the messages in the AMQ Broker console&lt;/h3&gt; &lt;p&gt;If you recall, when we created the broker using the &lt;b&gt;ActiveMQArtemis&lt;/b&gt; custom resource, we set the following attribute to expose the broker console:&lt;/p&gt; &lt;pre&gt;console: expose: true &lt;/pre&gt; &lt;p&gt;The broker pod in our deployment has a service that provides access to the console. This service has a corresponding route, &lt;code&gt;ex-aao-wconsj-0-svc-rte&lt;/code&gt;. To get the URL to access the broker console, Click on  &lt;strong&gt;Routes &lt;/strong&gt;under &lt;strong&gt;Networking&lt;/strong&gt; over on the left navigation pane&lt;b&gt;. &lt;/b&gt;You&amp;#8217;ll see two routes. Click the link that corresponds to this route as shown in Figure 16&lt;/p&gt; &lt;div id="attachment_768067" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-768067" class="wp-image-768067 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig16-1-1024x404.png" alt="Routes screen with the ex-aao route circled." width="640" height="253" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig16-1-1024x404.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig16-1-300x118.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig16-1-768x303.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-768067" class="wp-caption-text"&gt;Figure 16: Click the Location for the route you want.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Clicking the link opens a page that renders another link to the &lt;b&gt;Management Console&lt;/b&gt;. Click the link, which is shown in Figure 17.&lt;/p&gt; &lt;div id="attachment_737117" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig18.png"&gt;&lt;img aria-describedby="caption-attachment-737117" class="wp-image-737117" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig18.png" alt="Red Hat JBoss AMQ 7 main page with the Management Console link displayed first" width="640" height="265" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig18.png 955w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig18-300x124.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig18-768x318.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-737117" class="wp-caption-text"&gt;Figure 17: Click Management Console to go to AMQ Broker Management Console.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once you are in the Management Console, log in using &lt;code&gt;admin&lt;/code&gt; as your username and password, as shown in Figure 18.&lt;/p&gt; &lt;div id="attachment_737127" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig19.png"&gt;&lt;img aria-describedby="caption-attachment-737127" class="wp-image-737127" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig19.png" alt="A screenshot of the login page." width="640" height="365" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig19.png 815w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig19-300x171.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Fig19-768x438.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-737127" class="wp-caption-text"&gt;Figure 18: Log into the AMQ Broker Management Console with admin/admin.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;From the Management Console, click on &lt;b&gt;Artemis&lt;/b&gt; in the upper-left corner, then click &lt;b&gt;Queues&lt;/b&gt; in the top navigation bar. Notice the &lt;code&gt;test.foo&lt;/code&gt; address and queue that we created earlier, using the ActiveMQArtemisAddress custom resource. As shown in Figure 19, the message count should be 10.&lt;/p&gt; &lt;div id="attachment_768077" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig19.png"&gt;&lt;img aria-describedby="caption-attachment-768077" class="wp-image-768077 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig19-1024x293.png" alt="The Artemis AMQ Broker screen with Queues and 10 Message Count circled." width="640" height="183" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig19-1024x293.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig19-300x86.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Fig19-768x220.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-768077" class="wp-caption-text"&gt;Figure 19: There are now 10 messages in the test_foo queue.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Step 3: Consume the messages&lt;/h3&gt; &lt;p&gt;Use the following command to consume the 10 messages (change the URL and location of the truststore as needed):&lt;/p&gt; &lt;pre&gt;$ ./bin/artemis consumer --url 'amqps://ex-aao-amqp-0-svc-rte-amq-broker-ssl.apps.ocp42.lab.example:443?jms.username=admin&amp;#38;jms.password=admin&amp;#38;transport.trustStoreLocation=/opt/playground/amq76-ocp-deploy/client.ts&amp;#38;transport.trustStorePassword=password&amp;#38;transport.verifyHost=false' --threads 1 --protocol amqp --message-count 10 --destination 'queue://test.foo' Consumer:: filter = null Consumer ActiveMQQueue[test.foo], thread=0 wait until 10 messages are consumed Consumer ActiveMQQueue[test.foo], thread=0 Consumed: 10 messages Consumer ActiveMQQueue[test.foo], thread=0 Elapsed time in second : 0 s Consumer ActiveMQQueue[test.foo], thread=0 Elapsed time in milli second : 42 milli seconds Consumer ActiveMQQueue[test.foo], thread=0 Consumed: 10 messages Consumer ActiveMQQueue[test.foo], thread=0 Consumer thread finished &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: You&amp;#8217;ll need to change the URL and location of &lt;code&gt;client.ts&lt;/code&gt;. If you used a different password, change that too. Back in the broker management console, make sure that you are looking at the list of queues and click the &lt;b&gt;Reset&lt;/b&gt; button. The message count should be zero.&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;In this article, we walked through how to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Configure One-Way TLS with AMQ Broker&lt;/li&gt; &lt;li&gt;Install AMQ Broker Operator on OpenShift&lt;/li&gt; &lt;li&gt;Create a broker instance and TLS secured AMQL acceptor and define an Anycast address&lt;/li&gt; &lt;li&gt;Use the Apache Artemis CLI as a client to establish a secure connection to the broker and produce and consume messages&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;That&amp;#8217;s all. Hopefully, this article has been helpful.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F26%2Fconnecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift%2F&amp;#38;linkname=Connecting%20external%20clients%20to%20Red%20Hat%20AMQ%20Broker%20on%20Red%20Hat%20OpenShift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F26%2Fconnecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift%2F&amp;#38;linkname=Connecting%20external%20clients%20to%20Red%20Hat%20AMQ%20Broker%20on%20Red%20Hat%20OpenShift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F26%2Fconnecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift%2F&amp;#38;linkname=Connecting%20external%20clients%20to%20Red%20Hat%20AMQ%20Broker%20on%20Red%20Hat%20OpenShift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F26%2Fconnecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift%2F&amp;#38;linkname=Connecting%20external%20clients%20to%20Red%20Hat%20AMQ%20Broker%20on%20Red%20Hat%20OpenShift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F26%2Fconnecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift%2F&amp;#38;linkname=Connecting%20external%20clients%20to%20Red%20Hat%20AMQ%20Broker%20on%20Red%20Hat%20OpenShift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F26%2Fconnecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift%2F&amp;#38;linkname=Connecting%20external%20clients%20to%20Red%20Hat%20AMQ%20Broker%20on%20Red%20Hat%20OpenShift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F26%2Fconnecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift%2F&amp;#38;linkname=Connecting%20external%20clients%20to%20Red%20Hat%20AMQ%20Broker%20on%20Red%20Hat%20OpenShift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F26%2Fconnecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift%2F&amp;#038;title=Connecting%20external%20clients%20to%20Red%20Hat%20AMQ%20Broker%20on%20Red%20Hat%20OpenShift" data-a2a-url="https://developers.redhat.com/blog/2020/08/26/connecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift/" data-a2a-title="Connecting external clients to Red Hat AMQ Broker on Red Hat OpenShift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/26/connecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift/"&gt;Connecting external clients to Red Hat AMQ Broker on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/n-KevXCaiUc" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Developers deploying Red Hat AMQ on Red Hat OpenShift often wonder how to connect external clients to AMQ Broker using the Transport Layer Security (TLS) protocol, which is an improved successor to the Secure Sockets Layer (SSL) protocol. In this article, you will learn how to do just that. The steps are as follows: Generate [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/26/connecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift/"&gt;Connecting external clients to Red Hat AMQ Broker on Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">736427</post-id><dc:creator>Paul Vergilis</dc:creator><dc:date>2020-08-26T07:00:10Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/26/connecting-external-clients-to-red-hat-amq-broker-on-red-hat-openshift/</feedburner:origLink></entry><entry><title>Get started with JDK Flight Recorder in OpenJDK 8u</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/_2yZ734MjFI/" /><category term="Containers" /><category term="Java" /><category term="Linux" /><category term="Open source" /><category term="java garbage collection" /><category term="java monitoring" /><category term="jcmd" /><category term="JDK Flight Recorder" /><category term="OpenJDK" /><category term="OpenJDK 8" /><author><name>mtorre</name></author><id>https://developers.redhat.com/blog/?p=759487</id><updated>2020-08-25T07:00:43Z</updated><published>2020-08-25T07:00:43Z</published><content type="html">&lt;p&gt;The &lt;a href="https://developers.redhat.com/products/openjdk/download"&gt;OpenJDK 8u 262 release&lt;/a&gt; includes several security-related patches and a new addition, JDK Flight Recorder (JFR). This article introduces OpenJDK developers to using JDK Flight Recorder with JDK Mission Control and related utilities. I will also briefly introduce you to Project Hamburg, also known as Container JFR.&lt;/p&gt; &lt;h2&gt;About JDK Flight Recorder&lt;/h2&gt; &lt;p&gt;JDK Flight Recorder is a troubleshooting, monitoring, and profiling framework that is deeply embedded within the Java Virtual Machine (JVM) code. It was first introduced in OpenJDK 11 as part of &lt;a target="_blank" rel="nofollow" href="http://openjdk.java.net/jeps/328"&gt;JEP 328&lt;/a&gt;. JDK Flight Recorder was available before OpenJDK 11 as a commercial feature only in JRockit, and then in the Oracle distribution of the Java Development Kit (JDK). Since JFR was released as a proper open source component in OpenJDK 11, a growing number of &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; community members have wanted to make the feature available in older releases.&lt;/p&gt; &lt;p&gt;In 2019, during &lt;a target="_blank" rel="nofollow" href="https://archive.fosdem.org/2019/schedule/event/imc/"&gt;FOSDEM&amp;#8217;s Java DevRoom&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://openjdk.java.net/workshop"&gt;the OpenJDK Committers Workshop&lt;/a&gt;, a group of OpenJDK committers decided to form a joint task force with the goal of backporting the necessary changes and fixes to OpenJDK 8u. A little over a year and many, many patches later, the project was finally merged with the main upstream OpenJDK 8u development tree.&lt;/p&gt; &lt;p&gt;The first public release was OpenJDK 8u 262; however, if you attempt to compile OpenJDK yourself, you will find that OpenJDK 8u 262 defaults to skipping JFR during compilation. OpenJDK 8u 272 (due in October) will be the first release to compile JFR by default.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Developers who consume OpenJDK through &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; or &lt;a target="_blank" rel="nofollow" href="https://getfedora.org/"&gt;Fedora&lt;/a&gt; get a Red Hat Package Manager (RPM) file that contains support for JFR. We would certainly like to hear about your experiences, especially regarding bugs or issues that you find.&lt;/p&gt; &lt;h3&gt;JDK Flight Recorder under the hood&lt;/h3&gt; &lt;p&gt;JDK Flight Recorder consists of two main components: One is the critical part containing the data, and the other is the internal infrastructure to record and expose the data. This data is abstracted via a concept called &lt;a href="https://developers.redhat.com/topics/event-driven/"&gt;&lt;i&gt;events&lt;/i&gt;&lt;/a&gt;. Events can have many kinds of useful information associated with them and can represent samples in time, single-trigger events, or a given time duration. As a developer, you can add metadata as well as other contextual information to an event definition and use that information to describe the event for your analysis tools, and also make it self-descriptive for other humans to better understand the event type. For example, you might want to be notified when file access happens or when a garbage collection (GC) compaction phase begins, or to know how long a full garbage collection phase took. Such events might contain fields that can be annotated—for example, to represent a &lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/en/java/javase/11/docs/api/jdk.jfr/jdk/jfr/Period.html"&gt;Period&lt;/a&gt; or a &lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/en/java/javase/11/docs/api/jdk.jfr/jdk/jfr/Frequency.html"&gt;Frequency&lt;/a&gt;—which JFR&amp;#8217;s tooling lets you visualize in a particular way during analysis. OpenJDK 8u includes more than 160 events for you to record and analyze.&lt;/p&gt; &lt;p&gt;Although those events are recorded when they happen, JFR itself is not a real-time tool and does not stream events at the point of call. (There is a &lt;a target="_blank" rel="nofollow" href="https://openjdk.java.net/jeps/349"&gt;JFR Event Streaming API&lt;/a&gt; in later OpenJDKs, but its purpose is not to stream events in real-time.) Instead, the underlying framework stores events in thread-local buffers that are then written to a global ring buffer. When those buffers are filled, they are finally flushed to disk by a periodic thread, using a mechanism that resembles the mechanism used by transactional databases.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: While JFR&amp;#8217;s design might seem overly complicated, it allows for efficient use of both memory and CPU. Generally, JFR&amp;#8217;s overhead is extremely low—about 1%, and in most cases, even less. The low overhead means that JFR can be (and is) used at production time, unlike most other solutions where the runtime cost is more prohibitive.&lt;/p&gt; &lt;h3&gt;JFR recordings&lt;/h3&gt; &lt;p&gt;JFR&amp;#8217;s recording file is a binary representation of all of the events and their metadata. This information is divided into chunks. A &lt;em&gt;chunk&lt;/em&gt; is the smallest unit of self-contained information in a JFR recording that can be read separately and still completely describe the events contained within the chunk.&lt;/p&gt; &lt;p&gt;All of the information is encoded as LEB128 encoding integers, including strings that reference back to constant-pool positions. This encoding guarantees a high level of data compaction in each recording. You can also &lt;a target="_blank" rel="nofollow" href="http://hirt.se/blog/?p=1166"&gt;further compress&lt;/a&gt; recordings using methods like GZip, LZMA and XZ, or LZ4. Recordings are written to disk either on request or when the program terminates, based on configuration. You also can have endless recordings that are written to disk at intervals, letting you see the behavior of the application over time. In short, JFR&amp;#8217;s configuration options are flexible.&lt;/p&gt; &lt;h2&gt;How to use JDK Flight Recorder&lt;/h2&gt; &lt;p&gt;By default, a number of mechanisms are available to control JDK Flight Recorder in OpenJDK, which makes it extremely simple to adapt to the use case at hand. The first option is to start JFR directly with the JVM, for example:&lt;/p&gt; &lt;pre&gt;$ java -XX:StartFlightRecording your.application.ClassName&lt;/pre&gt; &lt;p&gt;You can use a comma-separated list of options to configure JFR further. As an example, you might want to dump the recording on exit:&lt;/p&gt; &lt;pre&gt;$ java -XX:StartFlightRecording=dumponexit=true your.application.ClassName&lt;/pre&gt; &lt;p&gt;You can use &lt;code&gt;jcmd&lt;/code&gt;, a utility you might already be familiar with, to control JFR after application startup:&lt;/p&gt; &lt;pre&gt;$ jcmd &amp;#60;pid&amp;#62; &amp;#60;pid&amp;#62;: The following commands are available: VM.unlock_commercial_features JFR.configure JFR.stop JFR.start JFR.dump JFR.check VM.native_memory ManagementAgent.stop ManagementAgent.start_local ManagementAgent.start VM.classloader_stats GC.rotate_log Thread.print GC.class_stats GC.class_histogram GC.heap_dump GC.finalizer_info GC.heap_info GC.run_finalization GC.run VM.uptime VM.dynlibs VM.flags VM.system_properties VM.command_line VM.version help For more information about a specific command use 'help &amp;#60;command&amp;#62;'. &lt;/pre&gt; &lt;p&gt;Intuitively, the &lt;code&gt;jcmd&lt;/code&gt; utility allows you to start and stop a recording, configure the recording settings, check the status of a recording, and dump a recording. It is possible to have multiple recordings running at the same time.&lt;/p&gt; &lt;p&gt;You can use the standard &lt;a target="_blank" rel="nofollow" href="https://docs.oracle.com/en/java/javase/14/jfapi/flight-recorder-api-programmers-guide.pdf"&gt;Java Flight Recorder API&lt;/a&gt; to access a recording directly from your application code. Some things are essential to understand when using the API, so I will discuss this option further and show you an example at the end of the article.&lt;/p&gt; &lt;p&gt;The other, arguably more useful method of retrieving recordings is via &lt;a target="_blank" rel="nofollow" href="http://jdk.java.net/jmc/"&gt;JDK Mission Control&lt;/a&gt;, an application specially designed to control and analyze recordings.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: You might have noticed the &lt;code&gt;unlock_commercial_features&lt;/code&gt; flag in the list of available &lt;code&gt;jcmd&lt;/code&gt; commands. It is important to be aware that JFR is &lt;i&gt;not&lt;/i&gt; a commercial feature in OpenJDK. It is, however, a commercial feature in any Oracle JDK before JDK 11. We&amp;#8217;ve kept the flag for compatibility reasons, but it does nothing, and you can safely ignore it.&lt;/p&gt; &lt;h2&gt;Using JDK Flight Recorder with JDK Mission Control&lt;/h2&gt; &lt;p&gt;OpenJDK contains a simple tool called &lt;code&gt;jfr&lt;/code&gt; that allows you to read JFR recordings and get useful metrics from them. However, you will see the real benefits of JFR recordings when you combine them with JDK Mission Control (JMC). JMC is already available in Fedora and &lt;a href="https://developers.redhat.com/products/rhel/"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) 7 via &lt;a href="https://developers.redhat.com/products/softwarecollections/overview"&gt;Red Hat Software Collections&lt;/a&gt; (RHSCL), in RHEL 8 via the modules, and for Windows users from the &lt;a href="https://developers.redhat.com/products/openjdk/download"&gt;OpenJDK developer portal&lt;/a&gt;. You can also obtain JDK Mission Control via a downstream distribution like &lt;a target="_blank" rel="nofollow" href="https://adoptopenjdk.net/jmc"&gt;AdoptOpenJDK&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;If you have an older installation of JMC, you might see a warning dialog when trying to access an OpenJDK 8u version with JDK Flight Recorder, asking if you are using a commercial feature. As I previously noted, you can ignore this message on OpenJDK (and on OpenJDK &lt;i&gt;only&lt;/i&gt;). This bug has been fixed in later versions of JDK Mission Control. Figure 1 shows the commercial features warning.&lt;/p&gt; &lt;div id="attachment_759507" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-1.png"&gt;&lt;img aria-describedby="caption-attachment-759507" class="wp-image-759507" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-1.png" alt="A screenshot of the commercial features warning." width="640" height="370" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-1.png 720w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-1-300x173.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-759507" class="wp-caption-text"&gt;Figure 1: You can ignore the commercial features warning on any OpenJDK build.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Demo: Profiling GC allocation&lt;/h2&gt; &lt;p&gt;JDK Mission Control Project Lead Marcus Hirt has prepared a fine &lt;a target="_blank" rel="nofollow" href="https://github.com/thegreystone/jmc-tutorial"&gt;set of tutorials&lt;/a&gt; and demos to explore using JFR and JMC together. Rather than creating a new demo, I will reference his code in this section. In particular, I will use his example of GC allocation behavior, &lt;code&gt;04_JFR_GC&lt;/code&gt;, to showcase JMC&amp;#8217;s ability to automatically analyze data and suggest improvements. JMC&amp;#8217;s analysis is based on a feature called the &lt;i&gt;rules engine&lt;/i&gt;. The rules engine is currently being &lt;a target="_blank" rel="nofollow" href="https://wiki.openjdk.java.net/display/jmc/Rules+2.0"&gt;overhauled&lt;/a&gt; for JMC 8.0 in order to add more options for analysis, offer a better API for direct consumption via tooling, and improve overall performance.&lt;/p&gt; &lt;p&gt;The GC demo simply allocates a lot of data and stores it in a map. It then checks the contents of the map at every allocation cycle. Although a real-world program would do something more interesting with the data, the pattern represents a very typical use case with hash maps. In our case, the program seems to work fine, and we don&amp;#8217;t experience any out-of-memory errors or other types of errors. That makes the demo a perfect candidate for exploring hidden performance problems and checking for possible bottlenecks and optimizations.&lt;/p&gt; &lt;h3&gt;Using templates&lt;/h3&gt; &lt;p&gt;JMC and JFR have a handy feature called &lt;i&gt;templates&lt;/i&gt; that allows you to start a recording with default settings and events. Those templates correspond to configurations that you can pass via the command-line interface (CLI) when retrieving recordings via &lt;code&gt;jcmd&lt;/code&gt;, for example. However, the graphical user interface (GUI) makes it much easier to understand the settings. We will choose the &lt;b&gt;profiling&lt;/b&gt; template and the default one-minute recording session for this experiment. That provides enough data for this demo.&lt;/p&gt; &lt;p&gt;As shown in Figure 2, running the application and retrieving the recording gives us a direct answer to what we might want to optimize right away, without the need to research further. The application does a significant number of primitive-to-object conversions, and JMC tells you where those allocations occur.&lt;/p&gt; &lt;div id="attachment_759517" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-2.png"&gt;&lt;img aria-describedby="caption-attachment-759517" class="wp-image-759517 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-2-1024x581.png" alt="A screenshot of analysis from JDK Mission Control's Automated Analysis view." width="640" height="363" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-2-1024x581.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-2-300x170.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-2-768x436.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-2.png 1052w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-759517" class="wp-caption-text"&gt;Figure 2: JDK Mission Control&amp;#8217;s Automated Analysis view detects many issues automatically.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This demo was created for a hands-on session at Java One some years ago, and the JMC version at that time did not have an option for advanced analysis. Students in the session were encouraged to explore the &lt;b&gt;Memory&lt;/b&gt; and the &lt;b&gt;TLAB&lt;/b&gt; tabs to get a more detailed indication of the memory pressure, which you can see in Figure 3.&lt;/p&gt; &lt;div id="attachment_759527" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-3.png"&gt;&lt;img aria-describedby="caption-attachment-759527" class="wp-image-759527 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-3-1024x567.png" alt="A screenshot of the memory allocation shown in the TLAB tab." width="640" height="354" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-3-1024x567.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-3-300x166.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-3-768x425.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-3.png 1343w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-759527" class="wp-caption-text"&gt;Figure 3: Memory allocations seen in the TLAB tab.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: The Analysis page in JMC 7 and later versions offers considerably more information, and is always improving with more rules and optimization strategies. JMC also provides the Analysis page as a standalone component exported as an HTML page. You can easily integrate JMC analysis into applications without using the full IDE. When used together with the JFR API, JMC&amp;#8217;s standalone analysis component lets you integrate robust monitoring and profiling solutions into your infrastructure while keeping memory overhead extremely low.&lt;/p&gt; &lt;h3&gt;Memory profiling with JFR&amp;#8217;s Old Object Sample Event&lt;/h3&gt; &lt;p&gt;Traditionally, for effective memory profiling, you would need to access and explore full heap dumps over time to check the GC roots and the allocation history. Another equally expensive option would be using methods like agents that sample object allocation via the Java Native Interface (JNI). That is not always possible, however, especially given the sensitive information contained in a full heap dump. JFR can help here, too, thanks to its Old Object Sample Event, which was backported to OpenJDK 8u.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you are interested in knowing more about JFR&amp;#8217;s Old Object Sample Event, I once again point you to a &lt;a target="_blank" rel="nofollow" href="http://hirt.se/blog/?p=1055"&gt;blog post by Marcus Hirt&lt;/a&gt;. You should really check out his blog. It&amp;#8217;s an incredible source of information, tricks, and details about profiling, JMC, and JFR.&lt;/p&gt; &lt;p&gt;We&amp;#8217;ll use another small and self-contained example to explore JFR&amp;#8217;s Old Object Sample Event. It&amp;#8217;s a rather obvious example when you read the code, but nevertheless very good for exploring our options.&lt;/p&gt; &lt;pre&gt;public class Leaks {    private static final Map&amp;#60;Object, Object&amp;#62; &lt;i&gt;SESSION_DATA &lt;/i&gt;= new HashMap&amp;#60;&amp;#62;();    public static class UserInformation {       private byte[] data = new byte[10000];    }    public static void main(String[] args) {        String userId = "user";        while (true) {            UserInformation user = (UserInformation) &lt;i&gt;SESSION_DATA&lt;/i&gt;.get(userId);            if (user == null) {                user = &lt;i&gt;findUserInformation&lt;/i&gt;(userId);                &lt;i&gt;// SESSION_DATA.put(userId, user); // Correct&lt;/i&gt; &lt;i&gt;               &lt;/i&gt;&lt;i&gt;SESSION_DATA&lt;/i&gt;.put(user, user);      &lt;i&gt;// Wrong&lt;/i&gt; &lt;i&gt;           &lt;/i&gt;}            &lt;i&gt;sleep&lt;/i&gt;();        }    }    private static UserInformation findUserInformation(String userId) {        &lt;i&gt;sleep&lt;/i&gt;();        return new UserInformation();    }    private static void sleep() {        try {            Thread.&lt;i&gt;sleep&lt;/i&gt;(1);        } catch (InterruptedException e) {}    } } &lt;/pre&gt; &lt;p&gt;The mistake highlighted in the code is the sort of error quick testing catches before going to production, but for the sake of example, let&amp;#8217;s assume it&amp;#8217;s a bug in our code that found its way into production. Figure 4 shows a JFR session where we&amp;#8217;ve turned on Old Object Sample Event profiling. (No heap dump was harmed during this session.)&lt;/p&gt; &lt;div id="attachment_759537" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-4.png"&gt;&lt;img aria-describedby="caption-attachment-759537" class="wp-image-759537" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-4.png" alt="A screenshot of an Old Object Sample Event shown in the Automated Analysis view" width="640" height="347" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-4.png 858w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-4-300x163.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-4-768x416.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-759537" class="wp-caption-text"&gt;Figure 4: An Old Object Sample Event is shown in the Automated Analysis view.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The analysis instantly tells us where to look: A hash map has been filled over and over, and not only contains an increasing number of objects, but the memory allocation is also high. Even without reading the code, you would expect this map to be filling objects in a loop without much control. As shown in Figure 5, the &lt;b&gt;Memory&lt;/b&gt; tab reveals even more.&lt;/p&gt; &lt;div id="attachment_759547" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-5.png"&gt;&lt;img aria-describedby="caption-attachment-759547" class="wp-image-759547 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-5-1024x521.png" alt="A screenshot of the Live Object page shown side-by-side with the application code." width="640" height="326" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-5-1024x521.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-5-300x153.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/openjdk-jfr-5-768x391.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-759547" class="wp-caption-text"&gt;Figure 5: The Live Object page is shown side-by-side with the application code. Note the matching line numbers.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In this tab, we see the program code alongside the &lt;b&gt;Live Object&lt;/b&gt; page. The stack trace with the line numbers points out exactly where the problem is.&lt;/p&gt; &lt;h3&gt;A note about profiling&lt;/h3&gt; &lt;p&gt;Being able to track object allocation and retention is one of the most critical tools when analyzing memory problems. I recall a bug that was challenging to fix because the number of created objects was huge, but only when running the application&amp;#8217;s UI via a remote X11 connection. In addition, objects were created every time the user moved the mouse or clicked a button, causing many methods to recalculate the position of the graphical interface, but only in some cases.&lt;/p&gt; &lt;p&gt;The two behaviors were linked because there was a bug in how we handled the remote connection: Calculating their position required knowing the relative position of objects on the screen. Because it was a remote connection, numerous X11 atoms were created and passed back and forth over the wire. If the user had multiple applications running, this would mean even more traffic. The Java code would end up intercepting those atoms, creating a Java representation, doing more calculations, and repeat.&lt;/p&gt; &lt;p&gt;At the time, we didn&amp;#8217;t have access to JMC, but to a similar tool called &lt;a target="_blank" rel="nofollow" href="http://icedtea.classpath.org/thermostat/"&gt;Thermostat&lt;/a&gt;. We used our integration with &lt;a target="_blank" rel="nofollow" href="https://byteman.jboss.org/"&gt;Byteman&lt;/a&gt; to create a script to analyze where those objects were created and why the code path that led to the creation of those objects was exercised differently. That is hard to do with regular method profilers because they tend to aggregate the results. Having this information handy directly from a JFR recording is incredibly important and would have saved us time. More so, when considering that a customer can simply send you the recording from their deployment rather than having you try to reproduce errors locally, install more tooling, open ports, start agents, and so on. In this case, the recording is all that is needed.&lt;/p&gt; &lt;h2&gt;The JDK Flight Recorder API&lt;/h2&gt; &lt;p&gt;Earlier, I mentioned that JFR comes with an internal API. The API resides under the &lt;code&gt;jdk.jfr&lt;/code&gt; namespace and contains classes that allow you to manage recordings and create custom events for your application.&lt;/p&gt; &lt;p&gt;The most straightforward program that you can write is for checking whether JFR is available:&lt;/p&gt; &lt;pre&gt;public class CheckJFR {    public static void main(String[] args) {        boolean isAvailable = FlightRecorder.&lt;i&gt;isAvailable&lt;/i&gt;();        System.&lt;i&gt;err&lt;/i&gt;.println(isAvailable);    } } &lt;/pre&gt; &lt;p&gt;You can then use the API to start and stop the recording programmatically from your application. For example, the following class is an abstraction to create a JFR manager:&lt;/p&gt; &lt;pre&gt;import java.io.File; import java.nio.file.Path; import java.util.HashMap; import java.util.Map; import jdk.jfr.Configuration; import jdk.jfr.Recording; public class LocalJFR {    private Map&amp;#60;Long, Recording&amp;#62; recordings = new HashMap&amp;#60;&amp;#62;();    @Override    public long startRecording(String configName) throws Exception {        Configuration c = Configuration.&lt;i&gt;getConfiguration&lt;/i&gt;(configName);        return startRecording(new Recording(c), "jfr-recording");    }    @Override    public long startRecording(String configName, String recordingName)        throws Exception    {        Configuration c = Configuration.&lt;i&gt;getConfiguration&lt;/i&gt;(configName);        return startRecording(new Recording(c), recordingName);    }    @Override    public long startRecording() throws Exception {        return startRecording(new Recording(), "jfr-reopenjdk-jfr-2cording");    }   public long startRecording(Recording recording, String name) throws Exception {       long id = recording.getId();          Path destination = File.&lt;i&gt;createTempFile&lt;/i&gt;(name + "-" + id,                                               ".jfr").toPath();        recording.setDestination(destination);        recordings.put(id, recording);        recording.start();        return id;    }    public File endRecording(long id) throws Exception {        Recording recording = recordings.remove(id);        recording.stop();        recording.close();        return recording.getDestination().toFile();    } } &lt;/pre&gt; &lt;p&gt;While this is the simplest event that you can define:&lt;/p&gt; &lt;pre&gt;@Label("Basic Event") @Description("An event with just a message as payload") public class BasicEvent extends Event {    @Label("Message")    public String message; }&lt;/pre&gt; &lt;h3&gt;Creating and monitoring JFR events programmatically&lt;/h3&gt; &lt;p&gt;Eric Gahlin, one of the authors of JFR in OpenJDK, put together a comprehensive list of demos and smaller tests using the &lt;a target="_blank" rel="nofollow" href="https://github.com/flight-recorder/samples"&gt;JFR API&lt;/a&gt;. The API is part of the Java specification starting from OpenJDK 11 but is not part of the specification in OpenJDK 8, so not all OpenJDK implementations will have access to it.&lt;/p&gt; &lt;p&gt;To facilitate porting and migration between versions, we created a simple &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/openjdk8-jfr-compat"&gt;compat-jfr&lt;/a&gt; with an empty implementation. This package allows users to instrument their code, create custom events, and use the API to manage recordings. The implementation is empty, however, so the methods don&amp;#8217;t do anything, events are not committed to memory or to disk, and when queried, JFR reports as not available and cannot be started. The application will function, compile, and run correctly, and is great for compatibility. You can use the compact-jfr either as a dependency on the command line or by adding it to your JDK&amp;#8217;s &lt;code&gt;jre/lib/ext&lt;/code&gt; directory.&lt;/p&gt; &lt;p&gt;In addition to creating custom events via the Event API, you can also instrument your code after the fact to add events to a running application. JMC also has a convenient tool for this, with the brilliant name of &lt;a target="_blank" rel="nofollow" href="https://wiki.openjdk.java.net/display/jmc/The+JMC+Agent"&gt;Agent&lt;/a&gt;. The JMC Agent uses a set of configurations to define events and then instruments the running code with them. Once the session is over, the instrumentation is removed. If you are familiar with Byteman (and you should be), Agent is very similar, but instead of a full Turing complete language at your disposal, Agent focuses on JFR events alone. The reduction in scope allows us to focus specifically on the problem of instrumenting JFR with more fine-tuned tools, which also partially solves issues like security and permissions. We are also working on a JMC plugin to control and configure Agent, it&amp;#8217;s a work in progress but is already useful and &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/jmc-agent-plugin"&gt;you can find it here&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Using JFR with containers (Project Hamburg)&lt;/h2&gt; &lt;p&gt;All of the tools described in this article are fantastic because they let you fine-tune JDK Flight Recorder for your specific deployment. However, we realized there is still a significant amount of work required from developers using JFR within &lt;a href="https://developers.redhat.com/topics/containers/"&gt;containers&lt;/a&gt;. First and foremost, the receiving end of JFR needs to have an open connection via the Java Management Extensions (JMX). This connection can (and should) be secured, of course, but a container platform like &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; (OCP) could disallow or make it difficult to leave internal ports open to the external world. It is also complicated to track multiple processes at once without the use of higher-level tooling. OpenShift has the deployments console to help you with this task, but a more general solution is still needed.&lt;/p&gt; &lt;p&gt;For this reason, we created a project called &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;Container JFR&lt;/a&gt;, also known as Project Hamburg. Container JFR is a simple three-tier application that contains a controller agent that connects via JMX within the container to the various applications and exposes a web services interface to the external world. The JMX connection can be hidden within the container—even in a non-container world, i.e. can be behind a firewall—while the web services interface is secured via authentication. The interface allows you to control multiple JVMs from the same endpoint, so it&amp;#8217;s great with multiple deployments.&lt;/p&gt; &lt;p&gt;The other component is a web UI that uses web services. It adds simplicity to the management, but above all integrates the automated analysis feature from JMC, so that you can see the &lt;a href="https://developers.redhat.com/blog/category/performance/"&gt;application performance&lt;/a&gt; right away and only decide to download the recording if the analysis points to certain issues. The project also contains a &lt;a href="https://developers.redhat.com/blog/2020/07/10/generate-automated-grafana-metrics-dashboards-for-microprofile-apps/"&gt;Grafana&lt;/a&gt; data source that lets us create graphs within the browser (so that users can integrate recordings in their dashboards, for example); an experimental &lt;a target="_blank" rel="nofollow" href="https://prometheus.io"&gt;Prometheus&lt;/a&gt; exporter (which isn&amp;#8217;t the best way to consume the recordings but nevertheless can be useful); and last but not least, a comprehensive set of Operator APIs for OpenShift or Kubernetes. Using these Operator APIs allows you to install, run, and configure the project with a simple mouse click.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Gunnar Morling has written a comprehensive blog post about &lt;a target="_blank" rel="nofollow" href="https://github.com/gunnarmorling/jfr-custom-events"&gt;using custom, application-specific JFR events to monitor a REST API&lt;/a&gt;. The post illustrates the streaming API and custom JFR events, so I&amp;#8217;ll point you there for further details. Gunnar is the best!&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;JDK Flight Recorder is the first monitoring and profiling tool available for OpenJDK that can expose such a high level of information without adding a tax on the runtime system. JFR offers that level of information because it is deeply integrated within the JVM. Being able to create custom events using either the Event API or the Agent tool lets you take advantage of JFR from an application perspective, too, and not just from the runtime.&lt;/p&gt; &lt;p&gt;OpenJDK was a massive contribution of code to the public, and JDK Flight Recorder is arguably the most significant contribution since OpenJDK was open sourced. When Oracle open sourced JDK Flight Recorder and JDK Mission Control, they did an incredible service to the Java community, which should be acknowledged. The backport to OpenJDK 8u is finally bringing this infrastructure to all of the actively maintained versions of the OpenJDK.&lt;/p&gt; &lt;p&gt;Although we hope that you have migrated to a later version of OpenJDK to benefit from all of the additional features and performance improvements, the addition of JFR in your toolbox will help your applications perform better, faster, and more trouble-free on any version of OpenJDK.&lt;/p&gt; &lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;I would like to thank:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Marcus Hirt for his work as a project lead for the JDK Mission Control project. He truly sets the standard high when it comes to community engagement, and his blog is an incredible source of inspiration and knowledge.&lt;/li&gt; &lt;li&gt;Gunnar Morling for helping out and testing Container JFR early in its development and for his feedback and suggestions.&lt;/li&gt; &lt;li&gt;Red Hat&amp;#8217;s JDK Mission Control team for their amazing contributions to JMC, and for their work on Agent, the JFR Compact, and Container JFR.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Finally, a huge thank you to the original JDK Flight Recorder team for this fantastic technology, and to Oracle for open sourcing it. Speaking of amazing, did you know that JMC &lt;a target="_blank" rel="nofollow" href="http://hirt.se/blog/?p=1230"&gt;won the best Java Feature&lt;/a&gt; contest in 2020?&lt;/p&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;p&gt;Here are the resources mentioned in this article, as well as interesting additional links to presentations, articles, and source code that you can use to learn more about JDK Flight Recorder and JDK Mission Control:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://archive.fosdem.org/2019/schedule/event/imc/"&gt;An introduction to middleware application monitoring with Java Mission Control and Flight Recorder&lt;/a&gt; (FOSDEM presentation, 2019)&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://fosdem.org/2020/schedule/event/imc/"&gt;JMC &amp;#38; JFR—2020 vision&lt;/a&gt; (FOSDEM presentation, 2020)&lt;/li&gt; &lt;li&gt;More about the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/openjdk8-jfr-compat"&gt;JFR compatibility API for OpenJDK 8&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="http://hirt.se/blog/?p=364"&gt;Low overhead method profiling with Java Mission Control&lt;/a&gt; (Marcus Hirt, 2013)&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="http://hirt.se/blog/?p=1166"&gt;Compressing flight recordings&lt;/a&gt; (Marcus Hirt, 2019)&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://dzone.com/articles/using-java-flight-recorder-with-openjdk-11-1"&gt;Using Java Flight Recorder with OpenJDK 11&lt;/a&gt; (Laszlo Csontos, 2018)&lt;/li&gt; &lt;li&gt;More about the &lt;a target="_blank" rel="nofollow" href="https://github.com/rh-jmc-team/container-jfr"&gt;Container JFR project&lt;/a&gt;&lt;/li&gt; &lt;li&gt;More about &lt;a target="_blank" rel="nofollow" href="https://github.com/openjdk/jmc"&gt;JDK Mission Control&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Source code and examples for understanding how to create and use &lt;a target="_blank" rel="nofollow" href="https://github.com/gunnarmorling/jfr-custom-events"&gt;custom events with JDK Flight Recorder&lt;/a&gt; (Gunnar Morling, 2020)&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/flight-recorder/samples"&gt;Flight Recorder samples&lt;/a&gt;: Code snippets illustrating how to use the JDK Flight Recorder API&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/thegreystone/jmc-jshell"&gt;jmc-jshell&lt;/a&gt;: An easier way to experiment with the JDK Flight Recorder and the JMC core classes&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://www.morling.dev/blog/introducing-jmfrx-a-bridge-from-jmx-to-jdk-flight-recorder/"&gt;Introduction to JmFrX: a small utility to capture JMX data with JDK Flight Recorder&lt;/a&gt; (Gunnar Morling, 2020)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F25%2Fget-started-with-jdk-flight-recorder-in-openjdk-8u%2F&amp;#38;linkname=Get%20started%20with%20JDK%20Flight%20Recorder%20in%20OpenJDK%208u" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F25%2Fget-started-with-jdk-flight-recorder-in-openjdk-8u%2F&amp;#38;linkname=Get%20started%20with%20JDK%20Flight%20Recorder%20in%20OpenJDK%208u" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F25%2Fget-started-with-jdk-flight-recorder-in-openjdk-8u%2F&amp;#38;linkname=Get%20started%20with%20JDK%20Flight%20Recorder%20in%20OpenJDK%208u" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F25%2Fget-started-with-jdk-flight-recorder-in-openjdk-8u%2F&amp;#38;linkname=Get%20started%20with%20JDK%20Flight%20Recorder%20in%20OpenJDK%208u" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F25%2Fget-started-with-jdk-flight-recorder-in-openjdk-8u%2F&amp;#38;linkname=Get%20started%20with%20JDK%20Flight%20Recorder%20in%20OpenJDK%208u" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F25%2Fget-started-with-jdk-flight-recorder-in-openjdk-8u%2F&amp;#38;linkname=Get%20started%20with%20JDK%20Flight%20Recorder%20in%20OpenJDK%208u" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F25%2Fget-started-with-jdk-flight-recorder-in-openjdk-8u%2F&amp;#38;linkname=Get%20started%20with%20JDK%20Flight%20Recorder%20in%20OpenJDK%208u" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F25%2Fget-started-with-jdk-flight-recorder-in-openjdk-8u%2F&amp;#038;title=Get%20started%20with%20JDK%20Flight%20Recorder%20in%20OpenJDK%208u" data-a2a-url="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u/" data-a2a-title="Get started with JDK Flight Recorder in OpenJDK 8u"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u/"&gt;Get started with JDK Flight Recorder in OpenJDK 8u&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/_2yZ734MjFI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;The OpenJDK 8u 262 release includes several security-related patches and a new addition, JDK Flight Recorder (JFR). This article introduces OpenJDK developers to using JDK Flight Recorder with JDK Mission Control and related utilities. I will also briefly introduce you to Project Hamburg, also known as Container JFR. About JDK Flight Recorder JDK Flight Recorder [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u/"&gt;Get started with JDK Flight Recorder in OpenJDK 8u&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">759487</post-id><dc:creator>mtorre</dc:creator><dc:date>2020-08-25T07:00:43Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/25/get-started-with-jdk-flight-recorder-in-openjdk-8u/</feedburner:origLink></entry><entry><title>How to Install Red Hat Process Automation Manager 7.8</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/U9gwsOh3Uqs/how-to-install-rhpam-78.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-how_to_install_red_hat_process_automation_manager_7_8</id><updated>2020-08-25T05:00:06Z</updated><published>2020-08-25T05:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div&gt;&lt;div style="margin: 0px;"&gt;&lt;a href="https://1.bp.blogspot.com/-XtYIWE6HERs/XhNb1fqEqwI/AAAAAAAAw2A/SymJTAO25ts4tEjkEWGMA4dJl09Vi3HQwCNcBGAsYHQ/s1600/rhpam-login.png" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img alt="red hat process automation manager" border="0" data-blogger-escaped-data-original-height="927" data-blogger-escaped-data-original-width="1600" height="185" src="https://1.bp.blogspot.com/-XtYIWE6HERs/XhNb1fqEqwI/AAAAAAAAw2A/SymJTAO25ts4tEjkEWGMA4dJl09Vi3HQwCNcBGAsYHQ/s320/rhpam-login.png" title="" width="320" /&gt;&lt;/a&gt;Time for another update on installing the Red Hat Process Automation Manager with my easy install project.&amp;nbsp;&lt;/div&gt;&lt;div style="margin: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="margin: 0px;"&gt;Installing the latest process automation tooling for your development projects in just minutes on your very own machine has never been easier.&lt;/div&gt;&lt;div style="margin: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="margin: 0px;"&gt;It's done in just three easy steps, so let's take a closer look and see if I'm pulling your leg or telling the truth about how easy this installation can be.&lt;/div&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;div style="margin: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="margin: 0px;"&gt;Just three easy steps to a fully installed and configured Red Hat Process Automation manager.&lt;/div&gt;&lt;h2 data-blogger-escaped-data-sourcepos="6:1-8:122" dir="auto"&gt;Install on your machine&lt;/h2&gt;&lt;div style="margin: 0px;"&gt;&lt;a href="https://1.bp.blogspot.com/-2AAONrobo6Y/XhNbzlLbFYI/AAAAAAAAw18/UBkTqMie9dY-dEyUGSzMQLkFvFfRW_EZACNcBGAsYHQ/s1600/rhpam-business-central.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="red hat process automation manager" border="0" data-blogger-escaped-data-original-height="935" data-blogger-escaped-data-original-width="1600" height="186" src="https://1.bp.blogspot.com/-2AAONrobo6Y/XhNbzlLbFYI/AAAAAAAAw18/UBkTqMie9dY-dEyUGSzMQLkFvFfRW_EZACNcBGAsYHQ/s320/rhpam-business-central.png" style="cursor: move;" title="" width="320" /&gt;&lt;/a&gt;There are a few component you'll need to download for free from the provided developers site, then obtain the project linked below, add the&amp;nbsp; downloads, and run the installation script.&lt;/div&gt;&lt;div style="margin: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="margin: 0px;"&gt;Watch the installation unfold before your eyes, with configuration, settings, and user creation all detailed in the script output so you can learn from the installation.&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div style="margin: 0px;"&gt;Give it a try with these three steps:&lt;/div&gt;&lt;ol data-blogger-escaped-data-sourcepos="8:1-17:0" data-blogger-escaped-style="text-align: left;"&gt;&lt;li data-blogger-escaped-data-sourcepos="8:1-9:0"&gt;&lt;div data-blogger-escaped-data-sourcepos="8:4-8:122"&gt;&lt;div style="margin: 0px;"&gt;&lt;a href="https://gitlab.com/bpmworkshop/rhpam-install-demo/-/archive/master/rhpam-install-demo-master.zip"&gt;Download and unzip.&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;&lt;div data-blogger-escaped-data-sourcepos="8:4-8:122"&gt;&lt;div style="margin: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-blogger-escaped-data-sourcepos="10:1-11:0"&gt;&lt;div data-blogger-escaped-data-sourcepos="10:4-10:81"&gt;&lt;div style="margin: 0px;"&gt;Add products to installs directory, see installs/README for details and links.&lt;/div&gt;&lt;/div&gt;&lt;div data-blogger-escaped-data-sourcepos="10:4-10:81"&gt;&lt;div style="margin: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-blogger-escaped-data-sourcepos="14:1-15:0"&gt;&lt;div data-blogger-escaped-data-sourcepos="12:4-12:92"&gt;&lt;div style="margin: 0px;"&gt;Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges.&lt;/div&gt;&lt;/div&gt;&lt;div data-blogger-escaped-data-sourcepos="12:4-12:92"&gt;&lt;div style="margin: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&amp;nbsp;Login to&amp;nbsp;&lt;a data-blogger-escaped-target="_blank" href="http://localhost:8080/business-central" rel="nofollow noreferrer noopener"&gt;http://localhost:8080/business-central&lt;/a&gt;&amp;nbsp;(u:erics / p:redhatpam1!)&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;div style="margin: 0px;"&gt;That's it, not it's time to enjoy your installed and configured Red Hat Process Automation Manager.&lt;/div&gt;&lt;div&gt;&lt;div style="margin: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="margin: 0px;"&gt;Not sure how to get started with process automation? Try the&amp;nbsp;&lt;a href="https://bpmworkshop.gitlab.io/rhdm/index.html" rel="noreferrer noopener" target="_blank"&gt;online workshop&lt;/a&gt;&amp;nbsp;to get started building a first process automation project from scratch.&lt;/div&gt;&lt;div style="margin: 0px;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iOAi6EGneO4:qLtnr1PttEY:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iOAi6EGneO4:qLtnr1PttEY:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iOAi6EGneO4:qLtnr1PttEY:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=iOAi6EGneO4:qLtnr1PttEY:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iOAi6EGneO4:qLtnr1PttEY:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=iOAi6EGneO4:qLtnr1PttEY:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iOAi6EGneO4:qLtnr1PttEY:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=iOAi6EGneO4:qLtnr1PttEY:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iOAi6EGneO4:qLtnr1PttEY:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=iOAi6EGneO4:qLtnr1PttEY:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=iOAi6EGneO4:qLtnr1PttEY:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/iOAi6EGneO4" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/U9gwsOh3Uqs" height="1" width="1" alt=""/&gt;</content><summary>Time for another update on installing the Red Hat Process Automation Manager with my easy install project.  Installing the latest process automation tooling for your development projects in just minutes on your very own machine has never been easier. It's done in just three easy steps, so let's take a closer look and see if I'm pulling your leg or telling the truth about how easy this installation...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-08-25T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/iOAi6EGneO4/how-to-install-rhpam-78.html</feedburner:origLink></entry><entry><title>Java development on top of Kubernetes using Eclipse JKube</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Qg4WbCbuRw0/" /><category term="Developer Tools" /><category term="Java" /><category term="Kubernetes" /><category term="Spring Boot" /><category term="apache maven" /><category term="docker image" /><category term="Eclipse" /><category term="fabric8" /><category term="Jkube" /><category term="kubernetes manifest" /><category term="openshift" /><author><name>Rohan Kumar</name></author><id>https://developers.redhat.com/blog/?p=738437</id><updated>2020-08-24T07:00:56Z</updated><published>2020-08-24T07:00:56Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube"&gt;&lt;img class=" size-full wp-image-739047 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-23-12-19-21.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-23-12-19-21.png" alt="Eclipse JKube: Deploy maven applications to Kubernetes." width="316" height="101" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-23-12-19-21.png 316w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-23-12-19-21-300x96.png 300w" sizes="(max-width: 316px) 100vw, 316px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;It has been 25 years since developers started adopting Java technology and making it part of their core application stack. Today, many Java developers and Java-based shops are migrating or looking to migrate their infrastructure to &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;, or to related distributions like &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;Red Hat OpenShift&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://aws.amazon.com/eks/"&gt;Amazon EKS&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://kubernetes.io/"&gt;Kubernetes&lt;/a&gt; has a steep learning curve, however, and it adds an additional layer of operations to the familiar Java development workflow. In this article, I introduce &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube"&gt;Eclipse JKube&lt;/a&gt; and show you how to use it to simplify the Kubernetes workflow. As you&amp;#8217;ll see, Eclipse JKube provides a migration path to Kubernetes while letting you stay within the familiar Java ecosystem. I will also quickly show you how to deploy a Java application to OpenShift using OpenShift Maven plugin.&lt;/p&gt; &lt;h2&gt;The traditional Java development workflow&lt;/h2&gt; &lt;p&gt;In a traditional &lt;a href="https://developers.redhat.com/topics/enterprise-java/"&gt;Java&lt;/a&gt; workflow, shown in Figure 1, a Java developer writes code, creates deployment units in the form of JAR or WAR files, and deploys and runs these files in a web server or application server. Developers mostly use Maven from the command line or use an IDE such as IntelliJ or Eclipse to code and package their applications. Developers are accustomed to making changes to their code and trying things out before committing and pushing the code to a version control system.&lt;/p&gt; &lt;div id="attachment_738447" style="width: 583px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Traditional-Java-Development-1.png"&gt;&lt;img aria-describedby="caption-attachment-738447" class=" size-full wp-image-738447 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Traditional-Java-Development-1.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Traditional-Java-Development-1.png" alt="A diagram of the traditional Java development workflow." width="573" height="355" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Traditional-Java-Development-1.png 573w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Traditional-Java-Development-1-300x186.png 300w" sizes="(max-width: 573px) 100vw, 573px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-738447" class="wp-caption-text"&gt;Figure 1: The traditional Java development workflow.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;The cloud-native Java development workflow&lt;/h2&gt; &lt;p&gt;When we start writing cloud-native applications, Kubernetes and &lt;a href="https://developers.redhat.com/topics/containers/"&gt;containers&lt;/a&gt; come into the picture. As developers, we are expected to package our Java applications into &lt;a href="https://developers.redhat.com/blog/2020/06/08/commit-to-excellence-java-in-containers/"&gt;images&lt;/a&gt; and write Kubernetes manifests referencing those images. The manifests are then applied to the production server, which is running Kubernetes. Kubernetes pulls the images from the image registry and deploys applications based on the configuration we&amp;#8217;ve provided in our manifests, which are typically YAML files.&lt;/p&gt; &lt;p&gt;Figure 2 shows how the traditional Java development workflow changes in a cloud-native environment.&lt;/p&gt; &lt;div id="attachment_738457" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow.png"&gt;&lt;img aria-describedby="caption-attachment-738457" class=" size-full wp-image-738457 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow.png" alt="A diagram of the cloud-native Java development workflow." width="640" height="461" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow.png 813w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow-300x216.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow-768x553.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-738457" class="wp-caption-text"&gt;Figure 2: A cloud-native Java development workflow.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Eclipse JKube&lt;/h2&gt; &lt;p&gt;Adopting Kubernetes adds a new operations layer to the overall workflow, and that is troublesome for many developers. We want to focus on the application&amp;#8217;s logic, not how the application is deployed. Here is the point where &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube"&gt;Eclipse JKube&lt;/a&gt; enters the picture. As a developer, you can use JKube&amp;#8217;s libraries and plugins—&lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube/tree/master/jkube-kit"&gt;JKube Kit&lt;/a&gt; along with the &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube/tree/master/kubernetes-maven-plugin"&gt;Kubernetes Maven Plugin&lt;/a&gt; or the &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube/tree/master/openshift-maven-plugin"&gt;OpenShift Maven Plugin&lt;/a&gt;—to easily handle the Kubernetes and container operations outlined in Figure 2.&lt;/p&gt; &lt;p&gt;In the rest of this article, you will learn how to use Eclipse JKube with the Kubernetes Maven Plugin to simplify the Java development workflow on top of Kubernetes.&lt;/p&gt; &lt;h3&gt;Eclipse JKube in the cloud-native development workflow&lt;/h3&gt; &lt;p&gt;Let&amp;#8217;s consider a modified version of the cloud-native Java development workflow from Figure 2. Figure 3 shows that workflow after we&amp;#8217;ve integrated Eclipse JKube and the Kubernetes Maven Plugin.&lt;/p&gt; &lt;div id="attachment_738497" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow-Using-Eclipse-JKube.png"&gt;&lt;img aria-describedby="caption-attachment-738497" class=" size-full wp-image-738497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow-Using-Eclipse-JKube.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow-Using-Eclipse-JKube.png" alt="A diagram of the cloud-native Java workflow simplified with Eclipse JKube." width="640" height="461" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow-Using-Eclipse-JKube.png 813w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow-Using-Eclipse-JKube-300x216.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Cloud-Native-Java-Workflow-Using-Eclipse-JKube-768x553.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-738497" class="wp-caption-text"&gt;Figure 3: The cloud-native Java workflow simplified with Eclipse JKube.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In this workflow, all of the operations that require engaging with Kubernetes or a container (highlighted in red) are replaced by the default Eclipse JKube goals. Table 1 offers a closer look at these goals.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;Table 1: Default Eclipse JKube goals.&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Goal&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Phase&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Description&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#jkube:build"&gt;k8s:build&lt;/a&gt;&lt;/td&gt; &lt;td&gt;PRE_INTEGRATION_TEST&lt;/td&gt; &lt;td&gt;Build docker images.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#jkube:push"&gt;k8s:push&lt;/a&gt;&lt;/td&gt; &lt;td&gt;INSTALL&lt;/td&gt; &lt;td&gt;Push docker images to the registry.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#jkube:resource"&gt;k8s:resource&lt;/a&gt;&lt;/td&gt; &lt;td&gt;PROCESS_RESOURCES&lt;/td&gt; &lt;td&gt;Generate K8s manifests.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#jkube:apply"&gt;k8s:apply&lt;/a&gt;&lt;/td&gt; &lt;td&gt;COMPILE&lt;/td&gt; &lt;td&gt;Apply the generated manifests to K8s.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#jkube:undeploy"&gt;k8s:undeploy&lt;/a&gt;&lt;/td&gt; &lt;td&gt;UNDEPLOY&lt;/td&gt; &lt;td&gt;Delete K8s resources that were deployed via &lt;code&gt;k8s:apply&lt;/code&gt; and &lt;code&gt;k8s:deploy&lt;/code&gt;.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: If you don&amp;#8217;t want the opinionated defaults for your goals, then you can manually configure Eclipse JKube, which provides both &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#_xml_configuration"&gt;XML configuration&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#_resource_fragments"&gt;resource configuration&lt;/a&gt; options.&lt;/p&gt; &lt;p&gt;Now we&amp;#8217;re ready to explore an application example with Eclipse JKube and the Kubernetes Maven Plugin.&lt;/p&gt; &lt;h2&gt;Deploying a Java application onto Kubernetes with Eclipse JKube&lt;/h2&gt; &lt;p&gt;In this example, we will deploy a simple Java application onto a &lt;a target="_blank" rel="nofollow" href="https://kubernetes.io/docs/setup/learning-environment/minikube/"&gt;Minikube&lt;/a&gt; cluster using Eclipse JKube. Using the Kubernetes Maven Plugin, we can set up the deployment without providing any configuration.&lt;/p&gt; &lt;p&gt;For our example application, we&amp;#8217;ll use a &lt;a target="_blank" rel="nofollow" href="https://github.com/rohanKanojia/eclipse-jkube-demo-project"&gt;simple random number generation application&lt;/a&gt;. This application prints JSON output on a &lt;code&gt;/random&lt;/code&gt; endpoint, like this:&lt;/p&gt; &lt;pre&gt;~/work/repos/eclipse-jkube-demo-project : $ curl localhost:8080/random | jq . % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 45 0 45 0 0 818 0 --:--:-- --:--:-- --:--:-- 818 { "id": "e80a4d10-c79b-4b9a-aaac-7c286cb37f3c" } &lt;/pre&gt; &lt;h3&gt;Step 1: Get the Kubernetes Maven Plugin&lt;/h3&gt; &lt;p&gt;The Kubernetes Maven Plugin is available from the &lt;a target="_blank" rel="nofollow" href="https://search.maven.org/search?q=g:org.eclipse.jkube%20AND%20a:kubernetes-maven-plugin"&gt;Maven Central Repository&lt;/a&gt;. To start using Eclipse JKube, you need to add the Kubernetes Maven Plugin as a dependency in your &lt;code&gt;pom.xml&lt;/code&gt;, as shown here:&lt;/p&gt; &lt;pre&gt;&amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.eclipse.jkube&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;kubernetes-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;${jkube.version}&amp;#60;/version&amp;#62; &amp;#60;/plugin&amp;#62; &lt;/pre&gt; &lt;p&gt;If you are running the OpenShift version of Kubernetes, you will update your &lt;code&gt;pom.xml&lt;/code&gt; as follows:&lt;/p&gt; &lt;pre&gt;&amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.eclipse.jkube&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;openshift-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;${jkube.version}&amp;#60;/version&amp;#62; &amp;#60;/plugin&amp;#62; &lt;/pre&gt; &lt;h3&gt;Step 2: Build the docker image&lt;/h3&gt; &lt;p&gt;You can build your application JAR using the &lt;code&gt;mvn package&lt;/code&gt; command, then you can use the &lt;code&gt;mvn k8s:build&lt;/code&gt; goal to build a docker image of your application. Note that I am overriding the default image name via this property:&lt;/p&gt; &lt;pre&gt;&amp;#60;jkube.generator.name&amp;#62;docker.io/rohankanojia/random-generator:${project.version}&amp;#60;/jkube.generator.name&amp;#62; &lt;/pre&gt; &lt;p&gt;Before building an image, you need to make sure that you have exposed your docker daemon correctly. The command to expose the docker daemon is:&lt;/p&gt; &lt;pre&gt;$ eval $(minikube docker-env) &lt;/pre&gt; &lt;p&gt;Next, you enter the goal, &lt;code&gt;mvn k8s:build&lt;/code&gt;. Here is the output for building the docker image with the Eclipse JKube build goal:&lt;br /&gt; &lt;!-- HTML generated using hilite.me --&gt;&lt;/p&gt; &lt;div style="background: #ffffff; overflow: auto; width: auto; border: solid gray; border-width: .1em .1em .1em .8em; padding: .2em .6em;"&gt; &lt;pre style="margin: 0; line-height: 125%;"&gt;&lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ mvn k8s:build&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Scanning for projects...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ----------------------&amp;#60; meetup:random-generator &amp;#62;-----------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Building random-generator 0.0.1&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --------------------------------[ jar ]---------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --- kubernetes-maven-plugin:1.0.0-rc-1:build (default-cli) @ random-generator ---&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Running in Kubernetes mode&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Building Docker image in Kubernetes mode&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Running generator spring-boot&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: spring-boot: Using Docker image quay.io/jkube/jkube-java-binary-s2i:0.0.7 as base / builder&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: [docker.io/rohankanojia/random-generator:0.0.1] "spring-boot": Created docker-build.tar in 251 milliseconds&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: [docker.io/rohankanojia/random-generator:0.0.1] "spring-boot": Built image sha256:a20e5&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] BUILD SUCCESS&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Total time: 5.053 s&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Finished at: 2020-08-10T11:28:23+05:30&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $&lt;/span&gt;&lt;/pre&gt; &lt;/div&gt; &lt;h3&gt;Step 3: Push the image to your docker registry&lt;/h3&gt; &lt;p&gt;Once you&amp;#8217;ve built your docker image with your push registry configured (&lt;code&gt;docker.io&lt;/code&gt;, in my case), you can push the image to the registry. Here is the output after entering the Eclipse JKube push goal, &lt;code&gt;mvn k8s:push&lt;/code&gt;:&lt;/p&gt; &lt;p&gt;&lt;!-- HTML generated using hilite.me --&gt;&lt;/p&gt; &lt;div style="background: #ffffff; overflow: auto; width: auto; border: solid gray; border-width: .1em .1em .1em .8em; padding: .2em .6em;"&gt; &lt;pre style="margin: 0; line-height: 125%;"&gt;&lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ mvn k8s:push&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Scanning for projects...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ----------------------&amp;#60; meetup:random-generator &amp;#62;-----------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Building random-generator 0.0.1&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --------------------------------[ jar ]---------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --- kubernetes-maven-plugin:1.0.0-rc-1:push (default-cli) @ random-generator ---&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Running in Kubernetes mode&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Building Docker image in Kubernetes mode&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Running generator spring-boot&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: spring-boot: Using Docker image quay.io/jkube/jkube-java-binary-s2i:0.0.7 as base / builder&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: The push refers to repository [docker.io/rohankanojia/random-generator]&lt;/span&gt; &lt;span style="color: #888888;"&gt;5dcd9556710f: Layer already exists &lt;/span&gt; &lt;span style="color: #888888;"&gt;b7139ad07aa8: Layer already exists &lt;/span&gt; &lt;span style="color: #888888;"&gt;b6f081e4b2b6: Layer already exists &lt;/span&gt; &lt;span style="color: #888888;"&gt;d8e1f35641ac: Layer already exists &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: 0.0.1: digest: sha256:9f9eda2a13b8cab1d2c9e474248500145fc09e2922fe3735692f9bda4c76002d size: 1162&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Pushed docker.io/rohankanojia/random-generator:0.0.1 in 7 seconds &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] BUILD SUCCESS&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Total time: 11.222 s&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Finished at: 2020-08-10T11:35:37+05:30&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ &lt;/span&gt;&lt;/pre&gt; &lt;/div&gt; &lt;p&gt;After pushing the image, you can confirm that it was pushed to the specified image registry. In my case, I was able to see my pushed image on Docker Hub, as shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_738537" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-15-19-28-53.png"&gt;&lt;img aria-describedby="caption-attachment-738537" class=" size-full wp-image-738537 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-15-19-28-53-1024x577.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-15-19-28-53-1024x577.png" alt="A screenshot of the pushed image on Docker Hub." width="640" height="361" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-15-19-28-53-1024x577.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-15-19-28-53-300x169.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-15-19-28-53-768x433.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/06/Screenshot-from-2020-06-15-19-28-53.png 1344w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-738537" class="wp-caption-text"&gt;Figure 4: The pushed image is available on Docker Hub.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Step 4: Generate the Kubernetes resource manifests for your application&lt;/h3&gt; &lt;p&gt;After you&amp;#8217;ve built the application image, the next thing to do is to write the Kubernetes manifests. Eclipse JKube provides a goal for generating opinionated resource manifests based on the underlying Java framework, which could be &lt;a href="https://developers.redhat.com/topics/spring-boot"&gt;Spring Boot&lt;/a&gt;, &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt;, Vert.x, or some other framework. Another option is to configure the manifest using an XML configuration file and provide raw fragments (a portion of the desired resource manifest) in the application&amp;#8217;s &lt;code&gt;src/main/jkube&lt;/code&gt; folder. Your configuration would then be merged into the generated manifests.&lt;/p&gt; &lt;p&gt;For this application, we will let Eclipse JKube generate a manifest for a default deployment and a service of type &lt;code&gt;ClusterIP&lt;/code&gt;. Next, we&amp;#8217;ll customize the service manifest for a &lt;code&gt;Service&lt;/code&gt; of type &lt;code&gt;NodePort&lt;/code&gt;. Setting the following property overrides the default behavior:&lt;/p&gt; &lt;pre&gt;&amp;#60;jkube.enricher.jkube-service.type&amp;#62;NodePort&amp;#60;/jkube.enricher.jkube-service.type&amp;#62; &lt;/pre&gt; &lt;p&gt;Here is the output from entering the Eclipse JKube resource goal, &lt;code&gt;mvn k8s:resource&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;&lt;!-- HTML generated using hilite.me --&gt;&lt;/p&gt; &lt;div style="background: #ffffff; overflow: auto; width: auto; border: solid gray; border-width: .1em .1em .1em .8em; padding: .2em .6em;"&gt; &lt;pre style="margin: 0; line-height: 125%;"&gt;&lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ mvn k8s:resource&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Scanning for projects...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ----------------------&amp;#60; meetup:random-generator &amp;#62;-----------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Building random-generator 0.0.1&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --------------------------------[ jar ]---------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --- kubernetes-maven-plugin:1.0.0-rc-1:resource (default-cli) @ random-generator ---&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Running generator spring-boot&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: spring-boot: Using Docker image quay.io/jkube/jkube-java-binary-s2i:0.0.7 as base / builder&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: jkube-controller: Adding a default Deployment&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: jkube-service: Adding a default service 'random-generator' with ports [8080]&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: jkube-healthcheck-spring-boot: Adding readiness probe on port 8080, path='/actuator/health', scheme='HTTP', with initial delay 10 seconds&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: jkube-healthcheck-spring-boot: Adding liveness probe on port 8080, path='/actuator/health', scheme='HTTP', with initial delay 180 seconds&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: jkube-revision-history: Adding revision history limit to 2&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] BUILD SUCCESS&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Total time: 3.344 s&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Finished at: 2020-08-10T11:38:11+05:30&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ ls target/classes/META-INF/jkube/kubernetes&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator-deployment.yml random-generator-service.yml&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ cat target/classes/META-INF/jkube/kubernetes/random-generator-deployment.yml | head -n10&lt;/span&gt; &lt;span style="color: #888888;"&gt;---&lt;/span&gt; &lt;span style="color: #888888;"&gt;apiVersion: apps/v1&lt;/span&gt; &lt;span style="color: #888888;"&gt;kind: Deployment&lt;/span&gt; &lt;span style="color: #888888;"&gt;metadata:&lt;/span&gt; &lt;span style="color: #888888;"&gt; annotations:&lt;/span&gt; &lt;span style="color: #888888;"&gt; jkube.io/git-url: git@github.com:rohanKanojia/eclipse-jkube-demo-project.git&lt;/span&gt; &lt;span style="color: #888888;"&gt; jkube.io/git-commit: 1ef9ef2ef7a6fcbf8eb64c293f26f9c42d026512&lt;/span&gt; &lt;span style="color: #888888;"&gt; jkube.io/git-branch: master&lt;/span&gt; &lt;span style="color: #888888;"&gt; jkube.io/scm-url: https://github.com/spring-projects/spring-boot/spring-boot-starter-parent/random-generator&lt;/span&gt; &lt;span style="color: #888888;"&gt; jkube.io/scm-tag: HEAD&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $&lt;/span&gt;&lt;/pre&gt; &lt;/div&gt; &lt;h3&gt;Step 5: Deploy your application in a Kubernetes cluster&lt;/h3&gt; &lt;p&gt;Everything is now set up for the example application. We were able to generate the image for the application, and then automatically generate the resource manifests. Now, we only need to apply these artifacts onto a Kubernetes cluster. You could use &lt;code&gt;kubectl apply -f&lt;/code&gt; to deploy the application; however, the plugin also takes care of this for you. Here is the output after entering the Eclipse JKube apply goal, &lt;code&gt;mvn k8s:apply&lt;/code&gt;:&lt;!-- HTML generated using hilite.me --&gt;&lt;/p&gt; &lt;div style="background: #ffffff; overflow: auto; width: auto; border: solid gray; border-width: .1em .1em .1em .8em; padding: .2em .6em;"&gt; &lt;pre style="margin: 0; line-height: 125%;"&gt;&lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ mvn k8s:apply&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Scanning for projects...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ----------------------&amp;#60; meetup:random-generator &amp;#62;-----------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Building random-generator 0.0.1&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --------------------------------[ jar ]---------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --- kubernetes-maven-plugin:1.0.0-rc-1:apply (default-cli) @ random-generator ---&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Using Kubernetes at https://192.168.39.145:8443/ in namespace default with manifest /home/rohaan/work/repos/eclipse-jkube-demo-project/target/classes/META-INF/jkube/kubernetes.yml &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Using namespace: default&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Creating a Service from kubernetes.yml namespace default name random-generator&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Created Service: target/jkube/applyJson/default/service-random-generator.json&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Creating a Deployment from kubernetes.yml namespace default name random-generator&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Created Deployment: target/jkube/applyJson/default/deployment-random-generator.json&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: HINT: Use the command `kubectl get pods -w` to watch your pods start up&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] BUILD SUCCESS&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Total time: 7.306 s&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Finished at: 2020-08-10T11:40:57+05:30&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ kubectl get pods -w&lt;/span&gt; &lt;span style="color: #888888;"&gt;NAME READY STATUS RESTARTS AGE&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator-58b7847d7f-9m9df 0/1 Running 0 7s&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator-58b7847d7f-9m9df 1/1 Running 0 17s&lt;/span&gt; &lt;span style="color: #888888;"&gt;^C~/work/repos/eclipse-jkube-demo-project : $ kubectl get svc&lt;/span&gt; &lt;span style="color: #888888;"&gt;NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE&lt;/span&gt; &lt;span style="color: #888888;"&gt;io-openliberty-sample-getting-started NodePort 10.110.4.104 &amp;#60;none&amp;#62; 9080:30570/TCP 44h&lt;/span&gt; &lt;span style="color: #888888;"&gt;kubernetes ClusterIP 10.96.0.1 &amp;#60;none&amp;#62; 443/TCP 18d&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator NodePort 10.97.172.147 &amp;#60;none&amp;#62; 8080:32186/TCP 22s&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ curl `minikube ip`:32186/random | jq .&lt;/span&gt; &lt;span style="color: #888888;"&gt; % Total % Received % Xferd Average Speed Time Time Time Current&lt;/span&gt; &lt;span style="color: #888888;"&gt; Dload Upload Total Spent Left Speed&lt;/span&gt; &lt;span style="color: #888888;"&gt;100 45 0 45 0 0 1800 0 --:--:-- --:--:-- --:--:-- 1875&lt;/span&gt; &lt;span style="color: #888888;"&gt;{&lt;/span&gt; &lt;span style="color: #888888;"&gt; "id": "42e5571f-a20f-44b3-8184-370356581d10"&lt;/span&gt; &lt;span style="color: #888888;"&gt;}&lt;/span&gt;&lt;/pre&gt; &lt;/div&gt; &lt;h3&gt;Step 6: Undeploy an application from the Kubernetes cluster&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;undeploy&lt;/code&gt; goal is the opposite of the &lt;code&gt;apply&lt;/code&gt; goal. It just deletes all of the resources applied during the &lt;code&gt;apply&lt;/code&gt; phase. Here is the output after initiating Eclipse JKube undeploy goal, &lt;code&gt;mvn k8s:undeploy&lt;/code&gt;:&lt;/p&gt; &lt;p&gt;&lt;!-- HTML generated using hilite.me --&gt;&lt;/p&gt; &lt;div style="background: #ffffff; overflow: auto; width: auto; border: solid gray; border-width: .1em .1em .1em .8em; padding: .2em .6em;"&gt; &lt;pre style="margin: 0; line-height: 125%;"&gt;&lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ kubectl get all&lt;/span&gt; &lt;span style="color: #888888;"&gt;NAME READY STATUS RESTARTS AGE&lt;/span&gt; &lt;span style="color: #888888;"&gt;pod/random-generator-58b7847d7f-9m9df 1/1 Running 0 5m21s&lt;/span&gt; &lt;span style="color: #888888;"&gt;NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE&lt;/span&gt; &lt;span style="color: #888888;"&gt;service/kubernetes ClusterIP 10.96.0.1 &amp;#60;none&amp;#62; 443/TCP 18d&lt;/span&gt; &lt;span style="color: #888888;"&gt;service/random-generator NodePort 10.97.172.147 &amp;#60;none&amp;#62; 8080:32186/TCP 5m21s&lt;/span&gt; &lt;span style="color: #888888;"&gt;NAME READY UP-TO-DATE AVAILABLE AGE&lt;/span&gt; &lt;span style="color: #888888;"&gt;deployment.apps/random-generator 1/1 1 1 5m21s&lt;/span&gt; &lt;span style="color: #888888;"&gt;NAME DESIRED CURRENT READY AGE&lt;/span&gt; &lt;span style="color: #888888;"&gt;replicaset.apps/random-generator-58b7847d7f 1 1 1 5m21s&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ mvn k8s:undeploy&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Scanning for projects...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ----------------------&amp;#60; meetup:random-generator &amp;#62;-----------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Building random-generator 0.0.1&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --------------------------------[ jar ]---------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --- kubernetes-maven-plugin:1.0.0-rc-1:undeploy (default-cli) @ random-generator ---&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Using Kubernetes at https://192.168.39.145:8443/ in namespace default with manifest /home/rohaan/work/repos/eclipse-jkube-demo-project/target/classes/META-INF/jkube/kubernetes.yml &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Using namespace: default&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Deleting resource Deployment default/random-generator&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: Deleting resource Service default/random-generator&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] k8s: HINT: Use the command `kubectl get pods -w` to watch your pods start up&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] BUILD SUCCESS&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Total time: 3.412 s&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Finished at: 2020-08-10T11:46:22+05:30&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ kubectl get pods -w&lt;/span&gt; &lt;span style="color: #888888;"&gt;^C~/work/repos/eclipse-jkube-demo-project : $ kubectl get all&lt;/span&gt; &lt;span style="color: #888888;"&gt;NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE&lt;/span&gt; &lt;span style="color: #888888;"&gt;service/kubernetes ClusterIP 10.96.0.1 &amp;#60;none&amp;#62; 443/TCP 18d&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $&lt;/span&gt;&lt;/pre&gt; &lt;/div&gt; &lt;h2&gt;Do more with Eclipse JKube&lt;/h2&gt; &lt;p&gt;We&amp;#8217;ve covered the core goals provided by Eclipse JKube and the Kubernetes Maven Plugin. You can use these goals to ease your Java application development workflow on top of Kubernetes. If you don&amp;#8217;t like typing the goals repeatedly, you could simplify by adding a specified execution in the plugin configuration, like this:&lt;/p&gt; &lt;pre&gt;&amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.eclipse.jkube&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;kubernetes-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;${project.version}&amp;#60;/version&amp;#62; &amp;#60;executions&amp;#62; &amp;#60;execution&amp;#62; &amp;#60;goals&amp;#62; &amp;#60;goal&amp;#62;build&amp;#60;/goal&amp;#62; &amp;#60;goal&amp;#62;resource&amp;#60;/goal&amp;#62; &amp;#60;goal&amp;#62;apply&amp;#60;/goal&amp;#62; &amp;#60;/goals&amp;#62; &amp;#60;/execution&amp;#62; &amp;#60;/executions&amp;#62; &amp;#60;/plugin&amp;#62; &lt;/pre&gt; &lt;p&gt;I haven&amp;#8217;t covered all of the goals provided by Eclipse JKube and the Kubernetes Maven Plugin. Table 2 shows additional goals, which you could explore on your own.&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;Table 2: Additional Eclipse JKube goals.&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Goal&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;Phase&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#jkube:log"&gt;k8s:log&lt;/a&gt;&lt;/td&gt; &lt;td&gt;VALIDATE&lt;/td&gt; &lt;td&gt;Get the logs from your application running inside of Kubernetes.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#jkube:debug"&gt;k8s:debug&lt;/a&gt;&lt;/td&gt; &lt;td&gt;PACKAGE&lt;/td&gt; &lt;td&gt;Open the debug port so that you can debug an application running inside Kubernetes from your IDE.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#jkube:deploy"&gt;k8s:deploy&lt;/a&gt;&lt;/td&gt; &lt;td&gt;INSTALL&lt;/td&gt; &lt;td&gt;Fork the Install goal and apply your generated manifests onto a Kubernetes cluster, just like the Apply goal.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/kubernetes-maven-plugin#jkube:watch"&gt;k8s:watch&lt;/a&gt;&lt;/td&gt; &lt;td&gt;PACKAGE&lt;/td&gt; &lt;td&gt;Do an automatic hot deployment of your application by watching your application workspace.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Deploying Java applications to Red Hat OpenShift using OpenShift Maven Plugin&lt;/h2&gt; &lt;p&gt;You can use the &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/docs/openshift-maven-plugin"&gt;OpenShift Maven plugin&lt;/a&gt; to deploy the same application on Red Hat OpenShift. The only difference would be that the &lt;code&gt;k8s&lt;/code&gt; goal prefix would be replaced by the &lt;code&gt;oc&lt;/code&gt; goal prefix. The Kubernetes Maven plugin does &lt;a target="_blank" rel="nofollow" href="https://www.docker.com/get-started"&gt;docker&lt;/a&gt; builds by default, and the OpenShift Maven Plugin does &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/enterprise/3.0/using_images/s2i_images/index.html"&gt;S2I&lt;/a&gt; builds by default. I haven&amp;#8217;t made any changes in my project apart from removing the property &lt;code&gt;jkube.generator.name&lt;/code&gt; since I won&amp;#8217;t be needing it for push (OpenShift pushes the image to its internal registry during the build phase). Here is an example, but instead of running one goal separately, I will deploy all of the resources and goals at once:&lt;/p&gt; &lt;p&gt;&lt;!-- HTML generated using hilite.me --&gt;&lt;/p&gt; &lt;div style="background: #ffffff; overflow: auto; width: auto; border: solid gray; border-width: .1em .1em .1em .8em; padding: .2em .6em;"&gt; &lt;pre style="margin: 0; line-height: 125%;"&gt;&lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ mvn oc:build oc:resource oc:apply&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Scanning for projects...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ----------------------&amp;#60; meetup:random-generator &amp;#62;-----------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Building random-generator 0.0.1&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --------------------------------[ jar ]---------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --- openshift-maven-plugin:1.0.0-rc-1:build (default-cli) @ random-generator ---&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Using OpenShift build with strategy S2I&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Running in OpenShift mode&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Running generator spring-boot&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: spring-boot: Using Docker image quay.io/jkube/jkube-java-binary-s2i:0.0.7 as base / builder&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: [random-generator:0.0.1] "spring-boot": Created docker source tar /home/rohaan/work/repos/eclipse-jkube-demo-project/target/docker/random-generator/0.0.1/tmp/docker-build.tar&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Adding to Secret pullsecret-jkube&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Using Secret pullsecret-jkube&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Creating BuildServiceConfig random-generator-s2i for Source build&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Creating ImageStream random-generator&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Starting Build random-generator-s2i&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Waiting for build random-generator-s2i-1 to complete...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Caching blobs under "/var/cache/blobs".&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Getting image source signatures&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:cf0f3ebe9f536c782ab3835049cfbd9a663761ded9370791ef6ea3965c823aad&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:57de4da701b511cba33bbdc424757f7f3b408bea741ca714ace265da9b59191a&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:f320f94d91a064281f5127d5f49954b481062c7d56cce3b09910e471cf849050&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying config sha256:52d6788fcfdd39595264d34a3959464a5dabc1d4ef0ae188802b20fc2d6a857b&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Writing manifest to image destination&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Storing signatures&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Generating dockerfile with builder image quay.io/jkube/jkube-java-binary-s2i:0.0.7&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 1: FROM quay.io/jkube/jkube-java-binary-s2i:0.0.7&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 2: LABEL "io.openshift.build.source-location"="/tmp/build/inputs" "io.openshift.build.image"="quay.io/jkube/jkube-java-binary-s2i:0.0.7"&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 3: ENV JAVA_APP_DIR="/deployments" OPENSHIFT_BUILD_NAME="random-generator-s2i-1" OPENSHIFT_BUILD_NAMESPACE="default"&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 4: USER root&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 5: COPY upload/src /tmp/src&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 6: RUN chown -R 1000:0 /tmp/src&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 7: USER 1000&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 8: RUN /usr/local/s2i/assemble&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: INFO S2I source build with plain binaries detected&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: INFO S2I binary build from fabric8-maven-plugin detected&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: INFO Copying binaries from /tmp/src/deployments to /deployments ...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: random-generator-0.0.1.jar&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: INFO Copying deployments from deployments to /deployments...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: '/tmp/src/deployments/random-generator-0.0.1.jar' -&amp;#62; '/deployments/random-generator-0.0.1.jar'&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 9: CMD /usr/local/s2i/run&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: STEP 10: COMMIT temp.builder.openshift.io/default/random-generator-s2i-1:48795e41&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: time="2020-08-10T06:37:49Z" level=info msg="Image operating system mismatch: image uses \"\", expecting \"linux\""&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: time="2020-08-10T06:37:49Z" level=info msg="Image architecture mismatch: image uses \"\", expecting \"amd64\""&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Getting image source signatures&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:d8e1f35641acb80b562f70cf49911341dfbe8c86f4d522b18efbf3732aa74223&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:b6f081e4b2b6de8be4b1dec132043d14c121e968384dd624fb69c2c07b482edb&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:b7139ad07aa8ce4ed5a132f7c5cc9f1de0f5099b5e155027a23d57f7fbe78b16&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:98972fc90a1108315cc5b05b2c691a0849a149727a7b81e76bc847ac2c6d9714&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying config sha256:27aaadaf28e24856a66db962b88118b8222b61d79163dceeeed869f7289bc230&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Writing manifest to image destination&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Storing signatures&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: --&amp;#62; 27aaadaf28e&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: 27aaadaf28e24856a66db962b88118b8222b61d79163dceeeed869f7289bc230&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Getting image source signatures&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Pushing image image-registry.openshift-image-registry.svc:5000/default/random-generator:0.0.1 ...&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:f320f94d91a064281f5127d5f49954b481062c7d56cce3b09910e471cf849050&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:cf0f3ebe9f536c782ab3835049cfbd9a663761ded9370791ef6ea3965c823aad&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:57de4da701b511cba33bbdc424757f7f3b408bea741ca714ace265da9b59191a&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying blob sha256:98972fc90a1108315cc5b05b2c691a0849a149727a7b81e76bc847ac2c6d9714&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Copying config sha256:27aaadaf28e24856a66db962b88118b8222b61d79163dceeeed869f7289bc230&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Writing manifest to image destination&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Storing signatures&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Successfully pushed image-registry.openshift-image-registry.svc:5000/default/random-generator@sha256:aa9e1a380c04ef9174ba56459c13d44420ebe653ebf32884d60fe4306b17306d&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Push successful&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Build random-generator-s2i-1 in status Complete&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Found tag on ImageStream random-generator tag: sha256:aa9e1a380c04ef9174ba56459c13d44420ebe653ebf32884d60fe4306b17306d&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: ImageStream random-generator written to /home/rohaan/work/repos/eclipse-jkube-demo-project/target/random-generator-is.yml&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --- openshift-maven-plugin:1.0.0-rc-1:resource (default-cli) @ random-generator ---&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Using docker image name of namespace: default&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Running generator spring-boot&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: spring-boot: Using Docker image quay.io/jkube/jkube-java-binary-s2i:0.0.7 as base / builder&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: jkube-controller: Adding a default DeploymentConfig&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: jkube-service: Adding a default service 'random-generator' with ports [8080]&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: jkube-healthcheck-spring-boot: Adding readiness probe on port 8080, path='/actuator/health', scheme='HTTP', with initial delay 10 seconds&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: jkube-healthcheck-spring-boot: Adding liveness probe on port 8080, path='/actuator/health', scheme='HTTP', with initial delay 180 seconds&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: jkube-revision-history: Adding revision history limit to 2&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] --- openshift-maven-plugin:1.0.0-rc-1:apply (default-cli) @ random-generator ---&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Using OpenShift at https://api.crc.testing:6443/ in namespace default with manifest /home/rohaan/work/repos/eclipse-jkube-demo-project/target/classes/META-INF/jkube/openshift.yml &lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: OpenShift platform detected&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Using project: default&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Creating a Service from openshift.yml namespace default name random-generator&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Created Service: target/jkube/applyJson/default/service-random-generator.json&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Creating a DeploymentConfig from openshift.yml namespace default name random-generator&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Created DeploymentConfig: target/jkube/applyJson/default/deploymentconfig-random-generator.json&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: Creating Route default:random-generator host: null&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] oc: HINT: Use the command `oc get pods -w` to watch your pods start up&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] BUILD SUCCESS&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Total time: 01:07 min&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] Finished at: 2020-08-10T12:08:00+05:30&lt;/span&gt; &lt;span style="color: #888888;"&gt;[INFO] ------------------------------------------------------------------------&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ oc get pods -w&lt;/span&gt; &lt;span style="color: #888888;"&gt;NAME READY STATUS RESTARTS AGE&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator-1-deploy 1/1 Running 0 14s&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator-1-vnrm9 0/1 Running 0 11s&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator-s2i-1-build 0/1 Completed 0 1m&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator-1-vnrm9 1/1 Running 0 24s&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator-1-deploy 0/1 Completed 0 28s&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ oc get routes&lt;/span&gt; &lt;span style="color: #888888;"&gt;NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD&lt;/span&gt; &lt;span style="color: #888888;"&gt;random-generator random-generator-default.apps-crc.testing random-generator 8080 None&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $ curl random-generator-default.apps-crc.testing/random &lt;/span&gt; &lt;span style="color: #888888;"&gt; % Total % Received % Xferd Average Speed Time Time Time Current&lt;/span&gt; &lt;span style="color: #888888;"&gt; Dload Upload Total Spent Left Speed&lt;/span&gt; &lt;span style="color: #888888;"&gt;100 45 0 45 0 0 1666 0 --:--:-- --:--:-- --:--:-- 1730&lt;/span&gt; &lt;span style="color: #888888;"&gt;{&lt;/span&gt; &lt;span style="color: #888888;"&gt; "id": "d80052d9-2f92-43cb-b9eb-d7cffb879798"&lt;/span&gt; &lt;span style="color: #888888;"&gt;}&lt;/span&gt; &lt;span style="color: #888888;"&gt;~/work/repos/eclipse-jkube-demo-project : $&lt;/span&gt;&lt;/pre&gt; &lt;/div&gt; &lt;h2&gt;Watch a video demonstration&lt;/h2&gt; &lt;p&gt;For more about simplifying Kubernetes development with Eclipse JKube, watch this demonstration video. You&amp;#8217;ll learn how to quickly deploy a simple Spring Boot application onto Minikube:&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/z1-EX-G3bpc?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, I showed you how to use Eclipse JKube to simplify your Kubernetes workloads. You can visit the Eclipse JKube &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/jkube/"&gt;project website&lt;/a&gt; to learn more about this collection. If you like Eclipse JKube, please support us by spreading the word about it on &lt;a target="_blank" rel="nofollow" href="https://twitter.com/jkubeio"&gt;Twitter&lt;/a&gt;. You can also &lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/jkube"&gt;watch and star the Eclipse JKube project on GitHub&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F24%2Fjava-development-on-top-of-kubernetes-using-eclipse-jkube%2F&amp;#38;linkname=Java%20development%20on%20top%20of%20Kubernetes%20using%20Eclipse%20JKube" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F24%2Fjava-development-on-top-of-kubernetes-using-eclipse-jkube%2F&amp;#38;linkname=Java%20development%20on%20top%20of%20Kubernetes%20using%20Eclipse%20JKube" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F24%2Fjava-development-on-top-of-kubernetes-using-eclipse-jkube%2F&amp;#38;linkname=Java%20development%20on%20top%20of%20Kubernetes%20using%20Eclipse%20JKube" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F24%2Fjava-development-on-top-of-kubernetes-using-eclipse-jkube%2F&amp;#38;linkname=Java%20development%20on%20top%20of%20Kubernetes%20using%20Eclipse%20JKube" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F24%2Fjava-development-on-top-of-kubernetes-using-eclipse-jkube%2F&amp;#38;linkname=Java%20development%20on%20top%20of%20Kubernetes%20using%20Eclipse%20JKube" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F24%2Fjava-development-on-top-of-kubernetes-using-eclipse-jkube%2F&amp;#38;linkname=Java%20development%20on%20top%20of%20Kubernetes%20using%20Eclipse%20JKube" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F24%2Fjava-development-on-top-of-kubernetes-using-eclipse-jkube%2F&amp;#38;linkname=Java%20development%20on%20top%20of%20Kubernetes%20using%20Eclipse%20JKube" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F24%2Fjava-development-on-top-of-kubernetes-using-eclipse-jkube%2F&amp;#038;title=Java%20development%20on%20top%20of%20Kubernetes%20using%20Eclipse%20JKube" data-a2a-url="https://developers.redhat.com/blog/2020/08/24/java-development-on-top-of-kubernetes-using-eclipse-jkube/" data-a2a-title="Java development on top of Kubernetes using Eclipse JKube"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/24/java-development-on-top-of-kubernetes-using-eclipse-jkube/"&gt;Java development on top of Kubernetes using Eclipse JKube&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Qg4WbCbuRw0" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;It has been 25 years since developers started adopting Java technology and making it part of their core application stack. Today, many Java developers and Java-based shops are migrating or looking to migrate their infrastructure to Kubernetes, or to related distributions like Red Hat OpenShift and Amazon EKS. Kubernetes has a steep learning curve, however, [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/24/java-development-on-top-of-kubernetes-using-eclipse-jkube/"&gt;Java development on top of Kubernetes using Eclipse JKube&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">738437</post-id><dc:creator>Rohan Kumar</dc:creator><dc:date>2020-08-24T07:00:56Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/24/java-development-on-top-of-kubernetes-using-eclipse-jkube/</feedburner:origLink></entry><entry><title>Kubernetes-native Apache Kafka with Strimzi, Debezium, and Apache Camel (Kafka Summit 2020)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/jUCkpD9-4LI/" /><category term="CI/CD" /><category term="Event-Driven" /><category term="Kubernetes" /><category term="Operator" /><category term="Stream Processing" /><category term="change data capture" /><category term="database integration" /><category term="debezium" /><category term="Kafka connector" /><category term="kafkasummit" /><category term="kubernetes-native" /><author><name>Hugo Guerrero</name></author><id>https://developers.redhat.com/blog/?p=767187</id><updated>2020-08-21T07:00:57Z</updated><published>2020-08-21T07:00:57Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; has become the leading platform for building real-time data pipelines. Today, Kafka is heavily used for developing &lt;a href="https://developers.redhat.com/topics/event-driven/"&gt;event-driven applications&lt;/a&gt;, where it lets services communicate with each other through events. Using &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; for this type of workload requires adding specialized components such as Kubernetes Operators and connectors to bridge the rest of your systems and applications to the Kafka ecosystem.&lt;/p&gt; &lt;p&gt;In this article, we&amp;#8217;ll look at how the open source projects Strimzi, Debezium, and Apache Camel integrate with Kafka to speed up critical areas of Kubernetes-native development.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Red Hat is sponsoring the Kafka Summit 2020 virtual conference from August 24-25, 2020. See the end of this article for details.&lt;/p&gt; &lt;p&gt;&lt;span id="more-767187"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Kafka on Kubernetes with Strimzi&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://strimzi.io/"&gt;Strimzi&lt;/a&gt; is an open source project that is part of the &lt;a target="_blank" rel="nofollow" href="https://www.cncf.io/"&gt;Cloud Native Computing Foundation&lt;/a&gt; (CNCF) that makes it easier to move Apache Kafka workloads to the cloud. Strimzi relies on the abstraction layer provided by Kubernetes and the &lt;a href="https://developers.redhat.com/topics/kubernetes/operators/"&gt;Kubernetes Operator&lt;/a&gt; pattern. Its main focus is running &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Apache Kafka on Kubernetes&lt;/a&gt; while providing &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container&lt;/a&gt; images for Kafka, Zookeeper, and other components that are part of the Strimzi ecosystem.&lt;/p&gt; &lt;p&gt;Strimzi extends the Kubernetes API with Kafka-related custom resource definitions (CRDs). The main Kafka CRD describes a Kafka cluster to deploy, as well as the Zookeeper ensemble that is needed. But Strimzi is not just for the broker; you can also use it to create and configure topics, and create users to access those topics. Strimzi also supports the configuration for mirroring data between clusters using &lt;a target="_blank" rel="nofollow" href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-382%3A+MirrorMaker+2.0"&gt;Kafka MirrorMaker 2.0&lt;/a&gt; custom resources, as well as deploying and managing the &lt;a target="_blank" rel="nofollow" href="https://strimzi.io/docs/bridge/latest/"&gt;Strimzi Kafka Bridge&lt;/a&gt; for HTTP clients.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;&lt;b&gt;Learn more&lt;/b&gt;: &lt;/b&gt;&lt;a href="https://developers.redhat.com/blog/2020/08/14/introduction-to-strimzi-apache-kafka-on-kubernetes-kubecon-europe-2020/"&gt;Introduction to Strimzi: Apache Kafka on Kubernetes (KubeCon Europe 2020)&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Change data capture with Debezium&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://debezium.io/"&gt;Debezium&lt;/a&gt; is a set of distributed services that captures row-level changes in your databases so that your applications can see and respond to the changes. Debezium records all row-level changes committed to each database table in a transaction log. Applications simply read the transaction logs they&amp;#8217;re interested in and see all of the events in the order in which they occurred. Debezium is durable and fast, so apps can respond quickly and never miss an event, even when things go wrong.&lt;/p&gt; &lt;p&gt;Debezium provides connectors for monitoring the following databases:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;MySQL Connector&lt;/li&gt; &lt;li&gt;PostgreSQL Connector&lt;/li&gt; &lt;li&gt;MongoDB Connector&lt;/li&gt; &lt;li&gt;SQL Server Connector&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Debezium connectors record all events to a &lt;a href="https://developers.redhat.com/blog/2018/10/29/how-to-run-kafka-on-openshift-the-enterprise-kubernetes-with-amq-streams/"&gt;Red Hat AMQ Streams&lt;/a&gt; Kafka cluster. Applications then consume those events through AMQ Streams. Debezium uses the &lt;a href="https://developers.redhat.com/blog/2020/02/14/using-secrets-in-apache-kafka-connect-configuration/"&gt;Apache Kafka Connect&lt;/a&gt; framework, which makes all of Debezium&amp;#8217;s connectors into Kafka Connector source connectors. As such, they can be deployed and managed using AMQ Streams&amp;#8217; Kafka Connect custom Kubernetes resources.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Learn more&lt;/strong&gt;: &lt;a href="https://developers.redhat.com/blog/2020/04/14/capture-database-changes-with-debezium-apache-kafka-connectors/"&gt;Capture database changes with Debezium Apache Kafka connectors&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Kafka connectivity with Apache Camel Kafka Connect&lt;/h2&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/"&gt;Apache Camel&lt;/a&gt; community has built one of the &lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/blog/ASF-Report-2019/"&gt;busiest open source integration frameworks&lt;/a&gt; in the Apache Foundation ecosystem. Camel lets you quickly and easily integrate data consumer and producer systems. It also implements the most used &lt;a target="_blank" rel="nofollow" href="https://www.enterpriseintegrationpatterns.com/"&gt;enterprise integration patterns&lt;/a&gt; and incorporates popular interfaces and protocols as they emerge.&lt;/p&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/camel-kafka-connector/latest/index.html"&gt;Camel Kafka Connector&lt;/a&gt; subproject focuses on using Camel components as &lt;a href="https://developers.redhat.com/blog/2020/05/19/extending-kafka-connectivity-with-apache-camel-kafka-connectors"&gt;Kafka Connect connectors&lt;/a&gt;. To this end, the development team built a tiny layer between the Camel and Kafka frameworks, which allows you to easily use each Camel component as a Kafka connector in the Kafka ecosystem. More than 340 Camel Kafka connectors support integrations with everything from AWS S3 to Telegram and Slack. All of these connectors are available to use with Kafka without throwing a single line of code.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Learn more&lt;/strong&gt;: &lt;a href="https://developers.redhat.com/blog/2020/05/19/extending-kafka-connectivity-with-apache-camel-kafka-connectors/"&gt;Extending Kafka connectivity with Apache Camel Kafka connectors&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;New organizations are adopting Apache Kafka as an event backbone every day. Communities like Apache Camel are working on how to speed up development in key areas such as integration. The Debezium community provides specialized connectors that simplify integrating database-generated events from microservices or legacy applications into modern, event-driven architectures. Finally, CNCF projects like Strimzi make it easier to access the benefits of Kubernetes and deploy Apache Kafka workloads in a cloud-native way.&lt;/p&gt; &lt;p&gt;For those who want an open source development model with enterprise support, &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/products/integration"&gt;Red Hat Integration&lt;/a&gt; lets you deploy your Kafka-based event-driven architecture on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, the enterprise Kubernetes. &lt;a target="_blank" rel="nofollow" href="https://www.redhat.com/en/resources/amq-streams-datasheet"&gt;Red Hat AMQ Streams&lt;/a&gt;, Debezium, and the Apache Camel Kafka Connect connectors are all available with a Red Hat Integration subscription.&lt;/p&gt; &lt;h2&gt;Kafka Summit 2020&lt;/h2&gt; &lt;p&gt;If you want to know more about running Apache Kafka on Kubernetes, Red Hat is sponsoring the &lt;a target="_blank" rel="nofollow" href="https://kafka-summit.org/"&gt;Kafka Summit 2020&lt;/a&gt; virtual conference from August 24-25, 2020. You can join either of the following sessions (note that you must be registered to follow these links):&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;b&gt;Tuesday, August 25, 2020, at 10:00 a.m. PDT&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://kafkasummit.io/session-virtual/?v26dd132ae80017cdaf764437c30ebe6f10c1b1eeaab01165e44366654b368dfaeab6baf7e386a642ecb238989334530e=29357BABE872174F33FC8355B5D7F6CBA10F9416968BEE4F161E83F2847328787AEE868E65ECEAE3D43713051B9D2B3C"&gt;Change Data Capture Pipelines with Debezium and Kafka Streams&lt;/a&gt; by Debezium project lead Gunnar Morling.&lt;/li&gt; &lt;li&gt;&lt;b&gt;Tuesday, August 25, 2020, at 10:30 a.m. PDT&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://kafkasummit.io/session-virtual/?v26dd132ae80017cdaf764437c30ebe6f10c1b1eeaab01165e44366654b368dfaeab6baf7e386a642ecb238989334530e=21BEFF118082C7BD226CEA8B405E4A27DAC3D4A0A525C2F58BD5774B496BD7899376E76179D6BCF1CA17BC373DD0BE4C"&gt;Camel Kafka Connectors: Tune Kafka to &amp;#8220;Speak&amp;#8221; With (Almost) Everything&lt;/a&gt; by Apache Camel engineers Andrea Cosentino and Andrea Tarocchi.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;If you want to follow the conversation and talk with the presenters, I&amp;#8217;ll be hosting panel discussions with the engineering leads at these times:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Monday August 24, 2020 from 10:00 a.m. &amp;#8211; 11:00 a.m. PDT&lt;/li&gt; &lt;li&gt;Monday August 24, 2020 from 1:00 p.m. &amp;#8211; 2:00 p.m. PDT&lt;/li&gt; &lt;li&gt;Tuesday August 25, 2020 from 11:00 a.m. &amp;#8211; 12:00 p.m. PDT&lt;/li&gt; &lt;li&gt;Tuesday August 25, 2020 from 1:00 p.m. &amp;#8211; 2:00 p.m. PDT&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Finally, we will have more Red Hatters at the &lt;a target="_blank" rel="nofollow" href="https://kafkasummit.io/virtual-exhibitor/?v0326b739525aaf6a5900c153ea6485e67109462e8db159b156161fc07c7e3d8016769932b4c0398e64b5ea52edb3d1c5=56CC3380CBA86BDA1DB77B0F6C902F3EE409DC5CA6F71077702CE1C9452986BBE14B10CA443311D61A730309F78FE22B"&gt;sponsored booth&lt;/a&gt; throughout the event, to solve your questions regarding running Kafka on Kubernetes.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#38;linkname=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fkubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020%2F&amp;#038;title=Kubernetes-native%20Apache%20Kafka%20with%20Strimzi%2C%20Debezium%2C%20and%20Apache%20Camel%20%28Kafka%20Summit%202020%29" data-a2a-url="https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/" data-a2a-title="Kubernetes-native Apache Kafka with Strimzi, Debezium, and Apache Camel (Kafka Summit 2020)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/"&gt;Kubernetes-native Apache Kafka with Strimzi, Debezium, and Apache Camel (Kafka Summit 2020)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/jUCkpD9-4LI" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Apache Kafka has become the leading platform for building real-time data pipelines. Today, Kafka is heavily used for developing event-driven applications, where it lets services communicate with each other through events. Using Kubernetes for this type of workload requires adding specialized components such as Kubernetes Operators and connectors to bridge the rest of your systems [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/"&gt;Kubernetes-native Apache Kafka with Strimzi, Debezium, and Apache Camel (Kafka Summit 2020)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">767187</post-id><dc:creator>Hugo Guerrero</dc:creator><dc:date>2020-08-21T07:00:57Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/21/kubernetes-native-apache-kafka-with-strimzi-debezium-and-apache-camel-kafka-summit-2020/</feedburner:origLink></entry><entry><title>Improved configuration and more in Red Hat CodeReady Workspaces 2.3</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/mAGagwrmXjM/" /><category term="Developer Tools" /><category term="Java" /><category term="Kubernetes" /><category term="Security" /><category term="cluster proxy" /><category term="CodeReady Workspaces" /><category term="jboss" /><category term="Kubernetes secrets" /><category term="openshift" /><author><name>Parag Dave</name></author><id>https://developers.redhat.com/blog/?p=767977</id><updated>2020-08-21T07:00:28Z</updated><published>2020-08-21T07:00:28Z</published><content type="html">&lt;p&gt;Based on &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/che/getting-started/cloud/?sc_cid=701f2000000RtqCAAS"&gt;Eclipse Che&lt;/a&gt;, &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;Red Hat CodeReady Workspaces&lt;/a&gt; (CRW) is a &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;-native developer environment that supports cloud-native development. CodeReady Workspaces 2.3 is now available. For this release, we focused on improving CRW&amp;#8217;s configuration options, updating to the latest versions of IDE plugins, and adding new devfiles.&lt;/p&gt; &lt;p&gt;CodeReady Workspaces 2.3 is available on:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.0/html/installation_guide/installing-codeready-workspaces-on-openshift-3-using-the-operator_crw"&gt;OpenShift 3.11&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.3/html/installation_guide/installing_codeready_workspaces_on_openshift_container_platform"&gt;OpenShift 4.3&lt;/a&gt; and higher, including &lt;a href="https://developers.redhat.com/products/openshift/getting-started"&gt;OpenShift 4.5&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/products/dedicated/"&gt;OpenShift Dedicated&lt;/a&gt; 4.3, via the add-ons capability.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;span id="more-767977"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Two ways to inject secrets into workspaces&lt;/h2&gt; &lt;p&gt;Starting with CodeReady Workspaces 2.3, you can automatically mount encrypted &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; secrets that contain sensitive information such as user names, passwords, and authentication tokens into workspace &lt;a href="https://developers.redhat.com/topics/containers/"&gt;containers&lt;/a&gt;. To mount these secrets, you have to create them in OpenShift namespaces, where your workspace containers are created. Let us consider the two mechanisms for mounting secrets to their workspaces: mounting secrets as environment variables, and mounting secrets in a file.&lt;/p&gt; &lt;h3&gt;Mounting secrets as environment variables&lt;/h3&gt; &lt;p&gt;The following YAML file contains two secrets, which are associated with the &lt;code&gt;FIRST_ENV_VAR&lt;/code&gt; and &lt;code&gt;SECOND_ENV_VAR&lt;/code&gt; environment variables. These environment variables are set with the values of &lt;code&gt;myvalue1&lt;/code&gt; and &lt;code&gt;myvalue2&lt;/code&gt;, respectively. Once set, the variables will reside inside of a container named &lt;code&gt;maven&lt;/code&gt; in all of the workspaces that are created in the same OpenShift namespace as this YAML file:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: Secret metadata: name: mvn-settings-secret annotations: che.eclipse.org/target-container: maven che.eclipse.org/mount-as: env che.eclipse.org/firstkey_env-name: FIRST_ENV_VAR che.eclipse.org/secondkey_env-name: SECOND_ENV_VAR labels: … data: firstkey: myvalue1 secondkey: myvalue2 &lt;/pre&gt; &lt;h3&gt;Mounting secrets in a file&lt;/h3&gt; &lt;p&gt;The next sample file shows a secret that is mounted in a file called &lt;code&gt;settings.xml&lt;/code&gt;. The file is available to a container named &lt;code&gt;maven&lt;/code&gt; in all of the workspaces that are created in the same OpenShift namespace as this YAML file:&lt;/p&gt; &lt;pre&gt;apiVersion: v1 kind: Secret metadata: name: mvn-settings-secret labels: app.kubernetes.io/part-of: che.eclipse.org app.kubernetes.io/component: workspace-secret annotations: che.eclipse.org/target-container: maven che.eclipse.org/mount-path: /home/user/.m2/ che.eclipse.org/mount-as: file che.eclipse.org/automount-workspace-secret: true data: settings.xml: __&amp;#60;base64 encoded data content here&amp;#62;__ &lt;/pre&gt; &lt;h2&gt;OpenShift cluster-wide proxy support&lt;/h2&gt; &lt;p&gt;When you enable OpenShift with a cluster-wide egress proxy, CodeReady Workspaces now automatically honors that proxy for communication across its components and external services.&lt;/p&gt; &lt;h2&gt;Experimental workspace storage setting&lt;/h2&gt; &lt;p&gt;You can now set the CheCluster custom resource configuration property &lt;code&gt;CHE_WORKSPACE_STORAGE_AVAILABLE_TYPES&lt;/code&gt; with an experimental value of &lt;code&gt;async&lt;/code&gt;. This value provides a blend of ephemeral and persistent storage. It allows for faster I/O and retains workspace changes.&lt;/p&gt; &lt;h2&gt;Improved reliability for terminal connections&lt;/h2&gt; &lt;p&gt;We improved CodeReady Workspaces to prevent failed task execution due to the disposal of terminal connections.&lt;/p&gt; &lt;h2&gt;Devfile updates&lt;/h2&gt; &lt;p&gt;We updated the set of devfiles provided with CodeReady Workspaces for more recent versions of runtime images and stacks.&lt;/p&gt; &lt;p&gt;Look for a new devfile with &lt;a href="https://developers.redhat.com/products/eap/overview"&gt;Red Hat JBoss Enterprise Application Platform&lt;/a&gt; (JBoss EAP) XP 1.0, OpenJDK 11, and Maven 3.5. Wherever possible, we migrated the Java-based devfiles to JDK 11. (JBoss EAP is not included with these unless it is required.) We also updated the commands within devfiles with numbers that reflect the recommended sequence of their execution.&lt;/p&gt; &lt;h2&gt;IDE plugin updates&lt;/h2&gt; &lt;p&gt;We updated various IDE plugins provided with CodeReady Workspaces for their newer versions. Plugins for &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; language support, &lt;a target="_blank" rel="nofollow" href="https://marketplace.visualstudio.com/items?itemName=redhat.fabric8-analytics"&gt;application dependency analytics&lt;/a&gt;, project initializer, &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt; language support, and Sonarlint have all been updated.&lt;/p&gt; &lt;h2&gt;Get CodeReady Workspaces 2.3&lt;/h2&gt; &lt;p&gt;CodeReady Workspaces 2.3 is available now on OpenShift 3.11 and OpenShift 4.x:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;If you are using OpenShift 3.11, you can &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.0/html/installation_guide/installing-codeready-workspaces-on-openshift-3-using-the-operator_crw"&gt;find installation instructions here&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;If you are using OpenShift 4.x, you can install directly from the OpenShift OperatorHub and &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_codeready_workspaces/2.3/html/installation_guide/installing_codeready_workspaces_on_openshift_container_platform"&gt;follow the documentation here&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/codeready-workspaces/download"&gt;Download&lt;/a&gt; the CodeReady Workspaces command-line interface.&lt;/li&gt; &lt;li&gt;Check out the CodeReady Workspaces product page.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#38;linkname=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fimproved-configuration-and-more-in-red-hat-codeready-workspaces-2-3%2F&amp;#038;title=Improved%20configuration%20and%20more%20in%20Red%20Hat%20CodeReady%20Workspaces%202.3" data-a2a-url="https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/" data-a2a-title="Improved configuration and more in Red Hat CodeReady Workspaces 2.3"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/"&gt;Improved configuration and more in Red Hat CodeReady Workspaces 2.3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/mAGagwrmXjM" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Based on Eclipse Che, Red Hat CodeReady Workspaces (CRW) is a Red Hat OpenShift-native developer environment that supports cloud-native development. CodeReady Workspaces 2.3 is now available. For this release, we focused on improving CRW&amp;#8217;s configuration options, updating to the latest versions of IDE plugins, and adding new devfiles. CodeReady Workspaces 2.3 is available on: OpenShift 3.11 [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/"&gt;Improved configuration and more in Red Hat CodeReady Workspaces 2.3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">767977</post-id><dc:creator>Parag Dave</dc:creator><dc:date>2020-08-21T07:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/21/improved-configuration-and-more-in-red-hat-codeready-workspaces-2-3/</feedburner:origLink></entry><entry><title>‘Hello, World’ tutorial with Kubernetes Operators</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/9f2Ke3qBFMA/" /><category term="DevOps" /><category term="Go" /><category term="Kubernetes" /><category term="Operator" /><category term="kubernetes operator example" /><category term="kubernetes operator tutorial" /><category term="minikube" /><category term="operator-sdk" /><author><name>dsharma</name></author><id>https://developers.redhat.com/blog/?p=736247</id><updated>2020-08-21T07:00:11Z</updated><published>2020-08-21T07:00:11Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; Operators reduce the work of human operators or site reliability engineers. Rather than a half-baked definition, I refer you to this original definition from the creators of the Kubernetes &lt;a href="https://developers.redhat.com/topics/kubernetes/operators/"&gt;Operator&lt;/a&gt; Framework: &lt;a target="_blank" rel="nofollow" href="https://coreos.com/blog/introducing-operator-framework"&gt;&lt;em&gt;Operators are Kubernetes applications&lt;/em&gt;.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;When I started building Operators with the &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-sdk"&gt;operator-sdk&lt;/a&gt; I discovered several unknowns that were difficult to address. I decided to create a guided introduction to the Kubernetes Operator SDK.&lt;/p&gt; &lt;p&gt;Hang on tight.&lt;/p&gt; &lt;h2&gt;Getting started with Kubernetes Operators&lt;/h2&gt; &lt;p&gt;Developers use the Kubernetes Operator SDK to make and deploy complex applications in Kubernetes. In this article, for the sake of brevity and understanding, we will create a simple, &lt;a href="https://developers.redhat.com/blog/2020/06/26/migrating-a-namespace-scoped-operator-to-a-cluster-scoped-operator/"&gt;namespace-scoped Operator&lt;/a&gt; in &lt;a target="_blank" rel="nofollow" href="https://golang.org/"&gt;Golang&lt;/a&gt;. We will build a deployment and set up a service. We&amp;#8217;ll also create a custom controller reconciliation loop that will watch over our deployed resources.&lt;/p&gt; &lt;p&gt;The prerequisites for this guided journey are as follows:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Be familiar with any programming language, though knowledge of Golang will be helpful for this example.&lt;/li&gt; &lt;li&gt;Have &lt;a target="_blank" rel="nofollow" href="https://github.com/kubernetes/minikube"&gt;Minikube&lt;/a&gt; installed in your development environment&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Set up your environment&lt;/h2&gt; &lt;p&gt;We will start by installing the utilities we need to build the Operator.&lt;/p&gt; &lt;h3&gt;Set up Golang&lt;/h3&gt; &lt;p&gt;We will use Golang to build the Operator. &lt;a target="_blank" rel="nofollow" href="https://golang.org/dl/"&gt;Install Golang&lt;/a&gt;, and then configure the following environment settings, as well as any other settings that you prefer:&lt;/p&gt; &lt;pre&gt;$GOPATH=/your/preferred/path/ $GO111MODULE=on &lt;/pre&gt; &lt;p&gt;Next, verify the installation:&lt;/p&gt; &lt;pre&gt;# Verify $ go version go version go1.13.3 linux/amd64 &lt;/pre&gt; &lt;h3&gt;Set up the SDK&lt;/h3&gt; &lt;p&gt;We will use the Kubernetes Operator SDK to build our Operator. &lt;a target="_blank" rel="nofollow" href="https://v0-19-x.sdk.operatorframework.io/docs/install-operator-sdk/"&gt;Install the Operator SDK&lt;/a&gt;, then verify the installation:&lt;/p&gt; &lt;pre&gt;# Verify $ operator-sdk version operator-sdk version: "v0.17.0", commit: "2fd7019f856cdb6f6618e2c3c80d15c3c79d1b6c", kubernetes version: "unknown", go version: "go1.13.10 linux/amd64" &lt;/pre&gt; &lt;h2&gt;Build the Operator&lt;/h2&gt; &lt;p&gt;In this section, we&amp;#8217;ll build the Operator. After each instruction, I will share the file tree for the example so far. Please verify the file tree at each step to ensure that you are in sync with the example.&lt;/p&gt; &lt;h3&gt;Generate the example application code&lt;/h3&gt; &lt;p&gt;Head over to &lt;code&gt;$GOPATH/src/operators&lt;/code&gt; and run:&lt;/p&gt; &lt;pre&gt;$ operator-sdk new hello-operator &lt;/pre&gt; &lt;p&gt;This command generates the boilerplate code for our example application. The default Operator type is GO.&lt;/p&gt; &lt;p&gt;At this point, &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/tree/c7ec102fc9940af906fdc066902f129e2d578801"&gt;your file tree should look like this&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Add a custom resource definition&lt;/h3&gt; &lt;p&gt;We use custom resource definitions (CRDs) to introduce custom resources that are understandable by k8s deployments. The CRD for this example is as follows:&lt;/p&gt; &lt;pre&gt;$ operator-sdk add api --api-version=example.com/v1alpha1 --kind=Traveller &lt;/pre&gt; &lt;p&gt;Note that we use &lt;code&gt;api-version&lt;/code&gt;to connect to the example application&amp;#8217;s namespace Operator. The format is group/version. The &lt;code&gt;kind&lt;/code&gt; definition refers to custom &lt;code&gt;kind&lt;/code&gt; for the application example. It will be used by the custom resources (CRs) that we create next.&lt;/p&gt; &lt;p&gt;Your file tree &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/tree/39219cd2317be4390c46d335875ac70fdb8fec03"&gt;should now look like this&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Update the custom resources&lt;/h3&gt; &lt;p&gt;Specifications (specs) are like hardcoded configuration values, also known as the &lt;i&gt;desired state&lt;/i&gt; of the cluster. In order to create the specs for this example, we will edit the custom resources in two files.&lt;/p&gt; &lt;h4&gt;Update example.com_v1alpha1_traveller_cr.yaml&lt;/h4&gt; &lt;p&gt;In this file, we can add any custom values that we might need for our controller function. Here, we will add the Hello Kubernetes image created by Paul Bouwer. Figure 1 shows the updated file, which you can find at &lt;strong&gt;deploy &amp;#62; crds &amp;#62; example.com_v1alpha1_traveller_cr.yaml&lt;/strong&gt;.&lt;/p&gt; &lt;div id="attachment_756247" style="width: 429px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-756247" class="wp-image-756247 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_5oHAQxw85LpAKrnD2njS8g.png" alt="A screenshot of the example.com_v1alpha1_traveller_cr.yaml file." width="419" height="193" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_5oHAQxw85LpAKrnD2njS8g.png 419w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_5oHAQxw85LpAKrnD2njS8g-300x138.png 300w" sizes="(max-width: 419px) 100vw, 419px" /&gt;&lt;p id="caption-attachment-756247" class="wp-caption-text"&gt;Figure 1: Add custom values for the controller function.&lt;/p&gt;&lt;/div&gt; &lt;figure class="graf graf--figure"&gt;&lt;/figure&gt; &lt;h4&gt;Update traveller_types.go&lt;/h4&gt; &lt;p&gt;We use this file to bring custom values to the controllers. The variables are case sensitive, so keep the title case for all variables. For example:&lt;/p&gt; &lt;pre&gt;{Variable} {type} {json:"name in *_cr.yaml" }&lt;/pre&gt; &lt;p&gt;Figure 2 shows the updates to bring custom values to the controllers. This file should be in &lt;strong&gt;pkg &amp;#62; apis &amp;#62; example &amp;#62; v1aplha1 &amp;#62; traveller_types.go&lt;/strong&gt;.&lt;/p&gt; &lt;div id="attachment_763717" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA.png"&gt;&lt;img aria-describedby="caption-attachment-763717" class="wp-image-763717 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA-1024x168.png" alt="A screenshot of the traveller_types.go file." width="640" height="105" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA-1024x168.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA-300x49.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA-768x126.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_tGx2FKdMhlb51FPGSqrrUA.png 1200w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-763717" class="wp-caption-text"&gt;Figure 2: Add custom values to the controllers.&lt;/p&gt;&lt;/div&gt; &lt;figure&gt;&lt;/figure&gt; &lt;p&gt;To update the generated code for the given resource type, run the following:&lt;/p&gt; &lt;pre&gt;$ operator-sdk generate k8s &lt;/pre&gt; &lt;p&gt;After each edit in &lt;code&gt;*_types.go&lt;/code&gt;, you must update the CRD to add Open API validations against the newly introduced values. This process is completely automated, simply by entering the following command:&lt;/p&gt; &lt;pre&gt;$ operator-sdk generate crds &lt;/pre&gt; &lt;p&gt;You should now see &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/commit/bdf9f30d63855aa073a362e7c9414397454cdc7d"&gt;this diff&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Add the controller&lt;/h2&gt; &lt;p&gt;Controllers define the reconciliation logic and the cluster resources to watch. Any change in a resource that is being watched triggers a reconciliation in the controller. Here is the command to add the controller to your Operator SDK:&lt;/p&gt; &lt;pre&gt;&amp;#62;$ operator-sdk add controller --api-version=example.com/v1alpha1 --kind=Traveller&lt;/pre&gt; &lt;p&gt;As always, &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/commit/c6bed9a53486ec35a04248b91ea501e970ee410e"&gt;verify the code diff&lt;/a&gt; before moving on.&lt;/p&gt; &lt;p&gt;We added the controller with default settings, namely the default APIs, role-based access control (RBAC), and service accounts. Next, we will add the custom logic for creating the application deployment and services. Whatever logic we write should be &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Idempotence"&gt;idempotent&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Add custom logic to the Operator SDK&lt;/h2&gt; &lt;p&gt;We will add five custom functions to the Operator SDK:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L162-L199"&gt;backendDeployment&lt;/a&gt;: Deploys the pod and exposes it at port 8080.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L201-L233"&gt;backendService&lt;/a&gt;: Creates a new back-end service for the exposed port.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L235-L267"&gt;ensureDeployment&lt;/a&gt;: Ensures the presence of a deployment in the given namespace. Otherwise, it creates a deployment by calling &lt;code&gt;1&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L201-L233"&gt;ensureService&lt;/a&gt;: Ensures the back-end service is present and running in the given namespace. Otherwise, it creates the service by calling &lt;code&gt;2&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/77cf069f74a364405faf03424deefe96ee9d0b22/pkg/controller/traveller/traveller_controller.go#L126-L134"&gt;labels&lt;/a&gt;: Sets the labels on the deployment and pods.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/blob/master/pkg/controller/traveller/traveller_controller.go#L88-L124"&gt;Change the reconcile function&lt;/a&gt; to trigger the newly defined functions.&lt;/p&gt; &lt;p&gt;Your code diff &lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator/commit/77cf069f74a364405faf03424deefe96ee9d0b22"&gt;should now look like this&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Test the Operator locally&lt;/h2&gt; &lt;p&gt;We are done adding our custom logic and building up the functionality. Now, we will test the Operator locally:&lt;/p&gt; &lt;pre&gt;# Please deploy in Sequence only $ kubectl apply -f deploy/role.yaml $ kubectl apply -f deploy/service_account.yaml $ kubectl apply -f deploy/role_binding.yaml $ kubectl apply -f deploy/crds/example.com_travellers_crd.yaml $ kubectl apply -f deploy/crds/*_cr.yaml &lt;/pre&gt; &lt;p&gt;Assuming that all of the above artifacts deploy successfully, we can run the Operator locally:&lt;/p&gt; &lt;pre&gt;$ operator-sdk run up --local &lt;/pre&gt; &lt;p&gt;This command should start up the Operator. Make sure that all of the custom resources are deployed by checking them against the namespace. For brevity, we&amp;#8217;re using the default namespace:&lt;/p&gt; &lt;pre&gt;$ kubectl get all&lt;/pre&gt; &lt;p&gt;The results are shown in Figure 3 where k is an alias for kubectl.&lt;/p&gt; &lt;div id="attachment_763737" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_xZbkePASBx2PCLUpc-4Kcg.png"&gt;&lt;img aria-describedby="caption-attachment-763737" class="wp-image-763737" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_xZbkePASBx2PCLUpc-4Kcg.png" alt="the output of kubectl get all" width="640" height="296" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_xZbkePASBx2PCLUpc-4Kcg.png 714w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_xZbkePASBx2PCLUpc-4Kcg-300x139.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-763737" class="wp-caption-text"&gt;Figure 3: Get all Kubernetes resources deployed in the default namespace.&lt;/p&gt;&lt;/div&gt; &lt;figure&gt;&lt;/figure&gt; &lt;h2&gt;Test the service&lt;/h2&gt; &lt;p&gt;Finally, test the service in Minikube by opening up a tunnel:&lt;/p&gt; &lt;pre&gt;$ minikube service backend-service &lt;/pre&gt; &lt;p&gt;The results are shown in Figure 4.&lt;/p&gt; &lt;div id="attachment_763757" style="width: 623px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-763757" class="wp-image-763757 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_pXvimQD1cUe2-LnxjmvxVg.png" alt="A Screnshot for terminal window showing expected output of command. " width="613" height="133" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_pXvimQD1cUe2-LnxjmvxVg.png 613w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/1_pXvimQD1cUe2-LnxjmvxVg-300x65.png 300w" sizes="(max-width: 613px) 100vw, 613px" /&gt;&lt;p id="caption-attachment-763757" class="wp-caption-text"&gt;Figure 4: Get endpoint for backend-service deployed in Minikube.&lt;/p&gt;&lt;/div&gt; &lt;figure&gt;&lt;/figure&gt; &lt;p&gt;The Minikube tunnel should redirect us to the service that we just created:&lt;/p&gt; &lt;div id="attachment_756187" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-756187" class="wp-image-756187 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_30D09VyYFygRqLwvURjelg-1024x289.png" alt="A screenshot of the home screen for the 'Hello, world' Kubernetes application" width="640" height="181" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_30D09VyYFygRqLwvURjelg-1024x289.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_30D09VyYFygRqLwvURjelg-300x85.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/1_30D09VyYFygRqLwvURjelg-768x217.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-756187" class="wp-caption-text"&gt;Figure 5: Home screen for the &amp;#8216;Hello, world&amp;#8217; Kubernetes application.&lt;/p&gt;&lt;/div&gt; &lt;figure&gt;&lt;/figure&gt; &lt;p&gt;And that&amp;#8217;s it! You have just developed a basic Kubernetes Operator.&lt;/p&gt; &lt;h2&gt;Export the Operator&lt;/h2&gt; &lt;p&gt;For a real cluster deployment, you would also need to export the Operator:&lt;/p&gt; &lt;pre&gt;$ operator-sdk build docker_username/repo:v0.0.1 $ docker push docker_username/repo $ sed -i "" 's|REPLACE_IMAGE|quay.io/example/memcached-operator:v0.0.1|g' deploy/operator.yaml $ kubectl apply -f deploy/operator.yaml &lt;/pre&gt; &lt;p&gt;Once you export the Operator, you can publish it via Git or Source Control Management (SCM), zip and mail it, or whatever you need to do.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;I again want to emphasize that Operators exist to simplify complex application deployments on Kubernetes. Operators especially support day-to-day activities like upgrading and downgrading Kubernetes applications and more. The guided exercise in this article is a good starting point for working with Operators. See the references below to learn more. Also, check out the GitHub repository for this tutorial, &lt;i&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/deepak1725/hello-operator"&gt;Basic Operator for Beginners&lt;/a&gt;&lt;/i&gt;, which includes the complete example code for this article.&lt;/p&gt; &lt;h2&gt;Further references&lt;/h2&gt; &lt;p&gt;These additional references are useful for learning about Kubernetes Operators and the Operator Framework:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/books/kubernetes-operators/old/"&gt;&lt;i&gt;Kubernetes Operators: Automating the Container Orchestration Platform&lt;/i&gt;&lt;/a&gt; (O&amp;#8217;Reilly, April 2020)&lt;/li&gt; &lt;li&gt;Source code for the example application used in this article, &lt;a target="_blank" rel="nofollow" href="https://github.com/paulbouwer/hello-kubernetes/"&gt;Hello Kubernetes!&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#38;linkname=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F21%2Fhello-world-tutorial-with-kubernetes-operators%2F&amp;#038;title=%E2%80%98Hello%2C%20World%E2%80%99%20tutorial%20with%20Kubernetes%20Operators" data-a2a-url="https://developers.redhat.com/blog/2020/08/21/hello-world-tutorial-with-kubernetes-operators/" data-a2a-title="‘Hello, World’ tutorial with Kubernetes Operators"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/hello-world-tutorial-with-kubernetes-operators/"&gt;&amp;#8216;Hello, World&amp;#8217; tutorial with Kubernetes Operators&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/9f2Ke3qBFMA" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Kubernetes Operators reduce the work of human operators or site reliability engineers. Rather than a half-baked definition, I refer you to this original definition from the creators of the Kubernetes Operator Framework: Operators are Kubernetes applications. When I started building Operators with the operator-sdk I discovered several unknowns that were difficult to address. I decided [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/21/hello-world-tutorial-with-kubernetes-operators/"&gt;&amp;#8216;Hello, World&amp;#8217; tutorial with Kubernetes Operators&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><post-id xmlns="com-wordpress:feed-additions:1">736247</post-id><dc:creator>dsharma</dc:creator><dc:date>2020-08-21T07:00:11Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/21/hello-world-tutorial-with-kubernetes-operators/</feedburner:origLink></entry><entry><title>Sunsetting Louketo Project</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/iyfLkb-zu-8/sunsetting-louketo-project.adoc.html" /><category term="feed_group_name_keycloak" scheme="searchisko:content:tags" /><category term="feed_name_keycloak" scheme="searchisko:content:tags" /><author><name>Bruno Oliveira</name></author><id>searchisko:content:id:jbossorg_blog-sunsetting_louketo_project</id><updated>2020-08-21T00:00:00Z</updated><published>2020-08-21T00:00:00Z</published><content type="html">&lt;div class="paragraph"&gt; &lt;p&gt;After careful consideration, we have decided to pull the plug on Louketo and start the EOL procedure. The plan is during the next 3 months to fix only critical bugs and security issues. Everyone interested in capabilities provided by Louketo Proxy should look at &lt;a href="https://github.com/oauth2-proxy/oauth2-proxy"&gt;OAuth2 Proxy&lt;/a&gt; project which is providing a similar set of capabilities and has a healthy and active community.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="https://groups.google.com/g/keycloak-dev/c/oDyw94BWxM0/m/zc0J9R10BwAJ"&gt;A few months ago&lt;/a&gt;, the Keycloak team started Louketo — a joint effort to build a generic OAuth2 Proxy and possibly also begin an umbrella project for a set of OIDC related integration libraries. The initial set of goals has not worked out. Keycloak Gatekeeper and OAuth2 Proxy projects hoped to merge and join efforts but for various reasons, this has not worked out.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;With Louketo and OAuth2 proxy providing similar features, OAuth Proxy being a more popular project with a bigger community we reached a conclusion there&amp;#8217;s no reason to put more effort into Louketo, when we can just contribute there.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;What does it mean in practice?&lt;/p&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_faq"&gt;FAQ&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="sect2"&gt; &lt;h3 id="_will_louketo_proxy_be_no_longer_maintained_will_there_be_no_new_releases"&gt;Will Louketo Proxy be no longer maintained? Will there be no new releases?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Critical bug fixes will be merged and micro releases provided for the next 3 months. It is up to community members to step up and take over maintaining and driving this project further if they wish to do so. Please comment on the &lt;a href="https://github.com/louketo/louketo-proxy/issues/683"&gt;GitHub issue&lt;/a&gt; or contact the Keycloak team on the &lt;a href="https://groups.google.com/forum/#!forum/louketo"&gt;mailing list&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_are_there_any_alternatives_i_should_use_instead"&gt;Are there any alternatives I should use instead?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;OAuth2 Proxy is very close in a set of capabilities to Louketo Proxy and we highly suggest you investigate it as a replacement.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_how_do_i_migrate_to_oauth2_proxy"&gt;How do I migrate to OAuth2 Proxy?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;We’ll provide high-level guidance on how to migrate. Although unfortunately there is no comprehensive guide nor magical script. Some corner cases, specific configurations, and capabilities may not be fully covered or addressed in exactly the same way.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_why_are_you_abandoning_louketo_proxy_as_a_project"&gt;Why are you abandoning Louketo Proxy as a project?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Initial goals failed. Which were merging with OAuth2 Proxy and creating a wider set of OAuth2/OIDC integration libraries. Some individuals originally interested in collaboration took a step back. The end result is the Louketo project duplicating efforts and capabilities of other much more popular projects - OAuth2 Proxy. As we believe in OpenSource we just don’t want to follow NIH syndrome :)&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_i_would_like_to_keep_maintaining_louketo_what_should_i_do"&gt;I would like to keep maintaining Louketo - what should I do?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Please comment on the &lt;a href="https://github.com/louketo/louketo-proxy/issues/683"&gt;GitHub issue&lt;/a&gt; so others can join the discussion. We’ll take it from there :)&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="_what_happens_if_nobody_will_step_up_to_maintain_louketo"&gt;What happens if nobody will step up to maintain Louketo?&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;After 3 months Louketo repository will be archived and made read-only.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/iyfLkb-zu-8" height="1" width="1" alt=""/&gt;</content><summary>After careful consideration, we have decided to pull the plug on Louketo and start the EOL procedure. The plan is during the next 3 months to fix only critical bugs and security issues. Everyone interested in capabilities provided by Louketo Proxy should look at OAuth2 Proxy project which is providing a similar set of capabilities and has a healthy and active community. A few months ago, the Keycl...</summary><dc:creator>Bruno Oliveira</dc:creator><dc:date>2020-08-21T00:00:00Z</dc:date><feedburner:origLink>https://www.keycloak.org//2020/08/sunsetting-louketo-project.adoc.html</feedburner:origLink></entry><entry><title>JSON logging updates in Open Liberty 20.0.0.8</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Pri5hgLTv7E/" /><category term="DevOps" /><category term="Java" /><category term="Kubernetes" /><category term="Microservices" /><category term="ELK Stack" /><category term="http to json" /><category term="log analysis" /><category term="logformat" /><category term="OpenLiberty" /><author><name>Jakub Pomykala</name></author><id>https://developers.redhat.com/blog/?p=760857</id><updated>2020-08-20T07:00:01Z</updated><published>2020-08-20T07:00:01Z</published><content type="html">&lt;p&gt;With Open Liberty 20.0.0.8, you can now customize HTTP access log fields in JSON logs. This feature allows you to include fields from the &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute in your JSON logs. You also can write a JSON log file directly to &lt;code&gt;system.out&lt;/code&gt;, without wrapping it in a &lt;code&gt;liberty_message&lt;/code&gt; event.&lt;/p&gt; &lt;p&gt;I&amp;#8217;ll introduce these new features and get you started with using them in &lt;a target="_blank" rel="nofollow" href="https://openliberty.io/about"&gt;Open Liberty&lt;/a&gt; 20.0.0.8. To see the list of fixed bugs, visit the &lt;a href="https://github.com/OpenLiberty/open-liberty/issues?q=label%3Arelease%3A20008+label%3A%22release+bug%22+"&gt;GitHub repository for Open Liberty 20.0.0.8&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;How to run your apps with Open Liberty 20.0.0.8&lt;/h2&gt; &lt;p&gt;If you&amp;#8217;re using &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//guides/maven-intro.html"&gt;Maven&lt;/a&gt;, update the following coordinates to run your apps with Open Liberty 20.0.0.8:&lt;/p&gt; &lt;pre&gt; &amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;io.openliberty&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;openliberty-runtime&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;20.0.0.8&amp;#60;/version&amp;#62; &amp;#60;type&amp;#62;zip &amp;#60;/type&amp;#62; &amp;#60;/dependency&amp;#62; &lt;/pre&gt; &lt;p&gt;If you&amp;#8217;re using &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//guides/gradle-intro.html"&gt;Gradle&lt;/a&gt;, enter:&lt;/p&gt; &lt;pre&gt;dependencies { libertyRuntime group: 'io.openliberty', name: 'openliberty-runtime', version: '[20.0.0.8,)' } &lt;/pre&gt; &lt;p&gt;If you&amp;#8217;re using docker, enter:&lt;/p&gt; &lt;pre&gt;FROM open-liberty &lt;/pre&gt; &lt;p&gt;See the &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//downloads/"&gt;Open Liberty downloads page&lt;/a&gt; for a downloadable archive of Open Liberty 20.0.0.8.&lt;/p&gt; &lt;h2&gt;Customize HTTP access log fields in your JSON logs&lt;/h2&gt; &lt;p&gt;In Open Liberty, you have the option to format your server logs in either basic or JSON format. When logs are in JSON format, you must specify the sources (&lt;code&gt;message&lt;/code&gt;, &lt;code&gt;trace&lt;/code&gt;, &lt;code&gt;accessLog&lt;/code&gt;, &lt;code&gt;ffdc&lt;/code&gt;, or &lt;code&gt;audit&lt;/code&gt;) that you want to send to &lt;code&gt;messages.log&lt;/code&gt; or &lt;code&gt;console.log&lt;/code&gt; and &lt;code&gt;standard-out&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;In Open Liberty 20.0.0.8, we&amp;#8217;ve added the option to include fields from the &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute in your JSON logs. Previously, only selected fields were printed in these logs. Now, you can include other NCSA (National Center for Supercomputing Applications) access log fields in your JSON logs. This new feature lets you receive more informative logs that suit your needs.&lt;/p&gt; &lt;h3&gt;Customizing JSON access log fields&lt;/h3&gt; &lt;p&gt;When logs are in JSON format, you can use the new &lt;code&gt;jsonAccessLogFields&lt;/code&gt; logging attribute to specify whether you want your access logs to have the default set of fields or a custom set based on the HTTP &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute. You can use the &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute to define the log fields that you want. You can then send the logs to a log analysis tool, such as the ELK (Elasticsearch, Logstash, Kibana) stack.&lt;/p&gt; &lt;p&gt;As an example, you might specify that you wanted the user ID and request-time fields in your JSON access logs. You could then filter these fields by user ID in Kibana and track performance on a user-by-user basis.&lt;/p&gt; &lt;p&gt;To receive access logs, you must set the property &lt;code&gt;accessLogging&lt;/code&gt; or &lt;code&gt;httpAccessLogging&lt;/code&gt;. For example, you might set the following attributes in your &lt;code&gt;server.xml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &amp;#60;httpEndpoint id="defaultHttpEndpoint" httpPort="9080" httpsPort="9443" host="*"&amp;#62; &amp;#60;accessLogging logFormat='%R{W} %u %{my_cookie}C %s'/&amp;#62; &amp;#60;/httpEndpoint&amp;#62; &amp;#60;logging messageFormat="json" messageSource="message,accessLog" jsonAccessLogFields="logFormat"/&amp;#62; &lt;/pre&gt; &lt;p&gt;In the &lt;code&gt;messages.log&lt;/code&gt; file, your access logs would now contain the four fields specified in the &lt;code&gt;accessLogging logFormat&lt;/code&gt; attribute (elapsed time, user ID, cookie, and response code):&lt;/p&gt; &lt;pre&gt;{ "type": "liberty_accesslog", "host": "192.168.1.15", "ibm_userDir": "/you/jennifer.zhen.chengibm.com/libertyGit/open-liberty/dev/build.image/wlp/usr/", "ibm_serverName": "defaultServer", "ibm_cookie_my_cookie": "example_cookie", "ibm_responseCode": 200, "ibm_datetime": "2020-06-18T09:30:47.693-0400", "ibm_sequence": "1592487047653_0000000000001" } &lt;/pre&gt; &lt;p&gt;You can also integrate this new functionality with Open Liberty&amp;#8217;s &lt;code&gt;logstashCollector-1.0&lt;/code&gt; feature by adding the following to your &lt;code&gt;server.xml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; &amp;#60;featureManager&amp;#62; &amp;#60;feature&amp;#62;logstashCollector-1.0&amp;#60;/feature&amp;#62; &amp;#60;/featureManager&amp;#62; &amp;#60;logstashCollector jsonAccessLogFields="logFormat"&amp;#62; &amp;#60;/logstashCollector&amp;#62; &lt;/pre&gt; &lt;h3&gt;Complete list of the new access log fields&lt;/h3&gt; &lt;p&gt;This table describes the new fields available with the corresponding &lt;code&gt;logFormat&lt;/code&gt; token:&lt;/p&gt; &lt;table&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Field&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;logFormat token&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_remoteIP&lt;/td&gt; &lt;td&gt;Remote IP address; e.g., 127.0.0.1.&lt;/td&gt; &lt;td&gt;%a&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_bytesSent&lt;/td&gt; &lt;td&gt;Response size in bytes excluding headers.&lt;/td&gt; &lt;td&gt;%b&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_cookie_{cookiename}&lt;/td&gt; &lt;td&gt;Cookie value from the request.&lt;/td&gt; &lt;td&gt;%{cookieName}C or %C&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_requestElapsedTime&lt;/td&gt; &lt;td&gt;The elapsed time of the request: millisecond accuracy, microsecond precision.&lt;/td&gt; &lt;td&gt;%D&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_requestHeader_{headername}&lt;/td&gt; &lt;td&gt;Header value from the request.&lt;/td&gt; &lt;td&gt;%{headerName}i&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_responseHeader_{headername}&lt;/td&gt; &lt;td&gt;Header value from the response.&lt;/td&gt; &lt;td&gt;%{headerName}o&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_requestFirstLine&lt;/td&gt; &lt;td&gt;The first line of the request.&lt;/td&gt; &lt;td&gt;%r&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_requestStartTime&lt;/td&gt; &lt;td&gt;The start time of the request, in NCSA format.&lt;/td&gt; &lt;td&gt; &lt;p class="tableblock"&gt;%t&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_accessLogDatetime&lt;/td&gt; &lt;td&gt;The time when the message to the access log is queued to be logged, in normal NCSA format.&lt;/td&gt; &lt;td&gt;%{t}W&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;ibm_remoteUserID&lt;/td&gt; &lt;td&gt;Remote user according to the WebSphere Application Server specific $WSRU header.&lt;/td&gt; &lt;td&gt;%u&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;See the documentation for &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//docs/ref/config/#logging.html"&gt;Open Liberty logging&lt;/a&gt;, and &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//docs/20.0.0.7/log-trace-configuration.html"&gt;Open Liberty log and trace configuration&lt;/a&gt; for more information.&lt;/p&gt; &lt;h2&gt;Write pre-formatted JSON application logs directly to &lt;code&gt;System.out&lt;/code&gt; or &lt;code&gt;System.err&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;Prior to this release, Open Liberty embedded any pre-formatted JSON application logs written to &lt;code&gt;System.out&lt;/code&gt; or &lt;code&gt;System.err&lt;/code&gt; into the message field of a &lt;code&gt;liberty_message&lt;/code&gt; event. Now, you can write these logs directly to &lt;code&gt;System.out&lt;/code&gt; or &lt;code&gt;System.err&lt;/code&gt; without having them wrapped in a &lt;code&gt;liberty_message&lt;/code&gt; event. You can then send the logs to a log analysis tool, such as the ELK (Elasticsearch, Logstash, Kibana) stack.&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s an example of a pre-formatted JSON log prior to this release:&lt;/p&gt; &lt;pre&gt;{ "type":"liberty_message", "host":"192.168.0.119", "ibm_userDir":"\/you\/yushan.lin@ibm.com\/Documents\/archived-guide-log4j\/finish\/target\/liberty\/wlp\/usr\ ", "ibm_serverName":"log4j.sampleServer", "message":"{\n \"timeMillis\" : 1587666082123,\n \"thread\" : \"Default Executor-thread-8\",\n \"level\" : \"WARN\",\n \"loggerName\" : \"application.servlet.LibertyServlet\",\n \"message\" : \"hello liberty servlet warning message!\",\n \"endOfBatch\" : false,\n \"loggerFqcn\" : \"org.apache.logging.log4j.spi.AbstractLogger\",\n \"threadId\" : 53,\n \"threadPriority\" : 5\n}\r", "ibm_threadId":"00000035", "ibm_datetime":"2020-04-23T14:21:22.124-0400", "module":"SystemOut", "loglevel":"SystemOut", "ibm_methodName":"", "ibm_className":"", "ibm_sequence":"1587666082124_000000000001B", "ext_thread":"Default Executor-thread-8” } &lt;/pre&gt; &lt;p&gt;You can now output the JSON application logs so that they are not wrapped in &lt;code&gt;liberty_message&lt;/code&gt; events. Enable this functionality by setting &lt;code&gt;appsWriteJson="true"&lt;/code&gt; in the logging element of the &lt;code&gt;server.xml&lt;/code&gt;. Another option is to have it set from the moment the server starts by setting the &lt;code&gt;bootstrap.properties&lt;/code&gt; to: &lt;code&gt;com.ibm.ws.logging.apps.write.json=true&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;For more information about this new logging feature, see &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//docs/ref/config/#logging.html"&gt;Open Liberty logging&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Try Open Liberty 20.0.0.8 in Red Hat Runtimes now&lt;/h2&gt; &lt;p&gt;Open Liberty is part of the Red Hat Runtimes offering and is available to &lt;a href="https://access.redhat.com/products/red-hat-runtimes" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;Red Hat Runtimes subscribers&lt;/a&gt;. To learn more about deploying Open Liberty applications to OpenShift, take a look at our &lt;a href="https://openliberty.io/guides/cloud-openshift.html" target="_blank" target="_blank" rel="nofollow" noreferrer"&gt;Open Liberty guide: Deploying microservices to OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#38;linkname=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F20%2Fjson-logging-updates-in-open-liberty-20-0-0-8%2F&amp;#038;title=JSON%20logging%20updates%20in%20Open%20Liberty%2020.0.0.8" data-a2a-url="https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/" data-a2a-title="JSON logging updates in Open Liberty 20.0.0.8"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/"&gt;JSON logging updates in Open Liberty 20.0.0.8&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Pri5hgLTv7E" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;With Open Liberty 20.0.0.8, you can now customize HTTP access log fields in JSON logs. This feature allows you to include fields from the accessLogging logFormat attribute in your JSON logs. You also can write a JSON log file directly to system.out, without wrapping it in a liberty_message event. I&amp;#8217;ll introduce these new features and [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/"&gt;JSON logging updates in Open Liberty 20.0.0.8&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">760857</post-id><dc:creator>Jakub Pomykala</dc:creator><dc:date>2020-08-20T07:00:01Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/20/json-logging-updates-in-open-liberty-20-0-0-8/</feedburner:origLink></entry><entry><title>Multipath TCP on Red Hat Enterprise Linux 8.3: From 0 to 1 subflows</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/e_noUn9Fb-Q/" /><category term="DevOps" /><category term="Linux" /><category term="Open source" /><category term="Linux kernel" /><category term="MPTCP" /><category term="networking" /><category term="rhel 8" /><category term="rhel 8.3" /><author><name>Davide Caratti</name></author><id>https://developers.redhat.com/blog/?p=756817</id><updated>2020-08-19T07:00:07Z</updated><published>2020-08-19T07:00:07Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Multipath_TCP"&gt;Multipath TCP&lt;/a&gt; (MPTCP) extends traditional TCP to allow reliable end-to-end delivery over multiple simultaneous TCP paths, and is coming as a tech preview on &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; 8.3. This is the first of two articles for users who want to practice with the new MPTCP functionality on a live system. In this first part, we show you how to enable the protocol in the kernel and let client and server applications use the MPTCP sockets. Then, we run diagnostics on the kernel in a sample test network, where endpoints are using a single subflow.&lt;/p&gt; &lt;h2&gt;Multipath TCP in Red Hat Enterprise Linux 8&lt;/h2&gt; &lt;p&gt;Multipath TCP is a relatively new &lt;a target="_blank" rel="nofollow" href="https://tools.ietf.org/html/rfc8684"&gt;extension&lt;/a&gt; for the Transmission Control Protocol (TCP), and its official Linux implementation is &lt;a target="_blank" rel="nofollow" href="https://twitter.com/davem_dokebi/status/1220715287365943298"&gt;even more recent&lt;/a&gt;. Early users might want to know what to expect in RHEL 8.3. In this article, you will learn how to:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Enable the Multipath TCP protocol in the kernel.&lt;/li&gt; &lt;li&gt;Let an application open an &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt; socket.&lt;/li&gt; &lt;li&gt;Use &lt;code&gt;tcpdump&lt;/code&gt; to inspect MPTCP options with live traffic.&lt;/li&gt; &lt;li&gt;Inspect the subflow status with &lt;code&gt;ss&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Enabling Multipath TCP in the kernel&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://www.multipath-tcp.org/"&gt;Multipath TCP&lt;/a&gt; registers as an upper-layer protocol (ULP) for TCP. Users can ensure that &lt;code&gt;mptcp&lt;/code&gt; is available in the kernel by checking the available ULPs:&lt;/p&gt; &lt;pre&gt;# sysctl net.ipv4.tcp_available_ulp net.ipv4.tcp_available_ulp = espintcp mptcp &lt;/pre&gt; &lt;p&gt;Unlike upstream Linux, MPTCP is disabled in the default Red Hat Enterprise Linux (RHEL) 8.3 runtime. To enable the possibility of creating sockets, system administrators need to issue a proper &lt;code&gt;sysctl&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt;# sysctl -w net.mptcp.enabled=1 # sysctl net.mptcp.enabled net.mptcp.enabled = 1 &lt;/pre&gt; &lt;h2&gt;Preparing the system for its first MPTCP socket&lt;/h2&gt; &lt;p&gt;With MPTCP enabled in the RHEL 8.3 kernel, user-space programs have a new protocol available for the &lt;code&gt;socket&lt;/code&gt; system call. There are two potential use cases for the new protocol.&lt;/p&gt; &lt;h3&gt;Native MPTCP applications&lt;/h3&gt; &lt;p&gt;Applications supporting MPTCP natively can open a &lt;code&gt;SOCK_STREAM&lt;/code&gt; socket specifying &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt; as the protocol and &lt;code&gt;AF_INET&lt;/code&gt; or &lt;code&gt;AF_INET6&lt;/code&gt; as the address family:&lt;/p&gt; &lt;pre&gt;fd = socket(AF_INET, SOCK_STREAM, IPPROTO_MPTCP); &lt;/pre&gt; &lt;p&gt;After the application creates a socket, the kernel will operate one or more TCP subflows that will use the standard MPTCP option (&lt;code&gt;IANA number = 30&lt;/code&gt;). Client and server semantics are the same as those used by a regular TCP socket (meaning that they will use &lt;code&gt;bind()&lt;/code&gt;, &lt;code&gt;listen()&lt;/code&gt;, &lt;code&gt;connect()&lt;/code&gt;, and &lt;code&gt;accept()&lt;/code&gt;).&lt;/p&gt; &lt;h3&gt;Legacy TCP applications converted to MPTCP&lt;/h3&gt; &lt;p&gt;Most user-space applications have no knowledge of &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt;, nor would it be realistic to patch and rebuild all of them to add native support for MPTCP. Because of this, the community opted for using an eBPF program that wraps the &lt;code&gt;socket()&lt;/code&gt; system call and &lt;a target="_blank" rel="nofollow" href="https://github.com/multipath-tcp/mptcp_net-next/issues/18"&gt;overrides the value of &lt;code&gt;protocol&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In RHEL 8.3, this program will run on CPU groups so that system administrators can specify which applications should run MPTCP while others continue with TCP. We will discuss the eBPF helper upstream in the next weeks, but we want to support early RHEL 8.3 users who want to try their own applications with MPTCP.&lt;/p&gt; &lt;p&gt;You can use a &lt;a target="_blank" rel="nofollow" href="https://linux.die.net/man/1/stap"&gt;systemtap&lt;/a&gt; script as a workaround to intercept calls to &lt;code&gt;__sys_socket()&lt;/code&gt; in the kernel. You can then allow a kernel probe to replace &lt;code&gt;IPPROTO_TCP&lt;/code&gt; with &lt;code&gt;IPPROTO_MPTCP&lt;/code&gt;. You will need to add packages to install a probe in the kernel with &lt;code&gt;stap&lt;/code&gt;. You&amp;#8217;ll also use the good-old &lt;code&gt;ncat&lt;/code&gt; tool from the &lt;code&gt;nmap-ncat&lt;/code&gt; package to run the client and the server:&lt;/p&gt; &lt;pre&gt;# dnf -y install \ &amp;#62; kernel-headers \ &amp;#62; kernel-devel \ &amp;#62; kernel-debuginfo &amp;#62; kernel-debuginfo-common_x86_64 \ &amp;#62; systemtap-client \ &amp;#62; systemtap-client-devel \ &amp;#62; nmap-ncat &lt;/pre&gt; &lt;p&gt;Use the following command to start the &lt;code&gt;systemtap&lt;/code&gt; &lt;a target="_blank" rel="nofollow" href="https://github.com/multipath-tcp/mptcp_net-next/issues/18#issuecomment-650529642"&gt;script&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;# stap -vg mpctp.stap&lt;/pre&gt; &lt;h3&gt;Protocol smoke test: A single subflow using &lt;code&gt;ncat&lt;/code&gt;&lt;/h3&gt; &lt;p&gt;The test network topology shown in Figure 1 consists of a client and a server that run in separate namespaces, connected through a virtual ethernet device (&lt;code&gt;veth&lt;/code&gt;).&lt;/p&gt; &lt;div id="attachment_757817" style="width: 542px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-757817" class="wp-image-757817 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/07/mptcp-1-topology.png" alt="Illustration of a network test topology with the veth-ns-client server." width="532" height="147" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/07/mptcp-1-topology.png 532w, https://developers.redhat.com/blog/wp-content/uploads/2020/07/mptcp-1-topology-300x83.png 300w" sizes="(max-width: 532px) 100vw, 532px" /&gt;&lt;p id="caption-attachment-757817" class="wp-caption-text"&gt;Figure 1: A network topology for basic MPTCP testing.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Adding additional IP addresses will simulate multiple L4 paths between endpoints. First, the server opens a passive socket, listening on a TCP port:&lt;/p&gt; &lt;pre&gt;# ncat -l 192.0.2.1 4321&lt;/pre&gt; &lt;p&gt;Then, the client connects to the server:&lt;/p&gt; &lt;pre&gt;# ncat 192.0.2.1 4321&lt;/pre&gt; &lt;p&gt;From a functional point of view, the interaction is the same as using &lt;code&gt;ncat&lt;/code&gt; with regular TCP: When the user writes a line in the client&amp;#8217;s standard input, the server displays that line in the standard output. Similarly, typing a line in the server&amp;#8217;s standard input results in transmitting it back to the client&amp;#8217;s standard output. In this example, we use &lt;code&gt;ncat&lt;/code&gt; to send a &amp;#8220;&lt;code&gt;hello world (1)\n&lt;/code&gt;&amp;#8221; message to the server. It waits for a second, then sends back &amp;#8220;&lt;code&gt;hello world (2)\n&lt;/code&gt;,&amp;#8221; then it closes the connection.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Current Linux MPTCP does not support mixed IPv4/IPv6 addresses. Therefore, all addresses involved in client/server connectivity must belong to the same family.&lt;/p&gt; &lt;h2&gt;Capturing traffic and examining it with &lt;code&gt;tcpdump&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;The Red Hat Enterprise Linux 8 version of &lt;code&gt;tcpdump&lt;/code&gt; doesn&amp;#8217;t yet support dissecting MPTCP v1 suboptions in TCP headers. We can overcome this problem by building a binary from the upstream repository. Alternatively, we can replace it with a &lt;a target="_blank" rel="nofollow" href="https://copr.fedorainfracloud.org/coprs/dcaratti/tcpdump-mptcp/"&gt;more recent binary&lt;/a&gt;. With either of those changes, it&amp;#8217;s possible to inspect the MPTCP suboption.&lt;/p&gt; &lt;h3&gt;Three-way handshake: The MP_CAPABLE suboption&lt;/h3&gt; &lt;p&gt;During a three-way-handshake, the client and server exchange a 64-bit key using the &lt;code&gt;MP_CAPABLE&lt;/code&gt; suboption, which is visible in the output of &lt;code&gt;tcpdump&lt;/code&gt; in the braces ({}) after &lt;code&gt;mptcp capable&lt;/code&gt;. These keys are then used later to compute the DSN/DACK and token. The &lt;code&gt;MP_CAPABLE&lt;/code&gt; suboption that originates in the client is also present following a successful connection setup. It will be present until the server explicitly acknowledges it using a data sequence signal (DSS) suboption:&lt;/p&gt; &lt;pre&gt;# tcpdump -#tnnr capture.pcap 1 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [S], seq 1721499445, win 29200, options [mss 1460,sackOK,TS val 33385784 ecr 0,nop,wscale 7,mptcp capable v1], length 0 2 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [S.], seq 3341831007, ack 1721499446, win 28960, options [mss 1460,sackOK,TS val 4061152149 ecr 33385784,nop,wscale 7,mptcp capable v1 {0xbb206e3023b47a2d}], length 0 3 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [.], ack 1, win 229, options [nop,nop,TS val 33385785 ecr 4061152149,mptcp capable v1 {0x41923206b75835f5,0xbb206e3023b47a2d}], length 0 4 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [P.], seq 1:17, ack 1, win 229, options [nop,nop,TS val 33385785 ecr 4061152149,mptcp capable v1 {0x41923206b75835f5,0xbb206e3023b47a2d},nop,nop], length 16 &lt;/pre&gt; &lt;h3&gt;MPTCP-level sequence numbers: The DSS suboption&lt;/h3&gt; &lt;p&gt;After that, TCP segments will carry the DSS suboption that contains MPTCP sequence numbers. More specifically, we can observe the data sequence number (DSN) and data acknowledgment (DACK) values, as shown here:&lt;/p&gt; &lt;pre&gt;5 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [.], ack 17, win 227, options [nop,nop,TS val 4061152149 ecr 33385785,mptcp dss ack 1711754507747579648], length 0 6 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [P.], seq 17:33, ack 1, win 229, options [nop,nop,TS val 33386778 ecr 4061152149,mptcp dss ack 1331650533424046587 seq 1711754507747579648 subseq 17 len 16,nop,nop], length 16 7 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [.], ack 33, win 227, options [nop,nop,TS val 4061153142 ecr 33386778,mptcp dss ack 1711754507747579664], length 0 &lt;/pre&gt; &lt;p&gt;Using a single subflow, DSN and DACK increase by the same amount as the TCP sequence and acknowledgment numbers. When the connection ends, the subflows are closed with a &lt;code&gt;FIN&lt;/code&gt; packet, just like regular TCP flows would be. Because it also closes the MPTCP socket, the data &lt;code&gt;fin&lt;/code&gt; bit is set in the DSS suboption, as shown here:&lt;/p&gt; &lt;pre&gt;8 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [F.], seq 33, ack 1, win 229, options [nop,nop,TS val 33387798 ecr 4061153142,mptcp dss fin ack 1331650533424046587 seq 1711754507747579664 subseq 0 len 1,nop,nop], length 0 9 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [.], ack 34, win 227, options [nop,nop,TS val 4061154203 ecr 33387798,mptcp dss ack 1711754507747579664], length 0 10 IP 192.0.2.1.4321 &amp;#62; 192.0.2.2.44176: Flags [F.], seq 1, ack 34, win 227, options [nop,nop,TS val 4061162156 ecr 33387798,mptcp dss fin ack 1711754507747579664 seq 1331650533424046587 subseq 0 len 1,nop,nop], length 0 11 IP 192.0.2.2.44176 &amp;#62; 192.0.2.1.4321: Flags [.], ack 2, win 229, options [nop,nop,TS val 33395793 ecr 4061162156,mptcp dss ack 1331650533424046587], length 0&lt;/pre&gt; &lt;h2&gt;Inspecting subflow data with &lt;code&gt;ss&lt;/code&gt;&lt;/h2&gt; &lt;p&gt;Because MPTCP uses TCP as a transport protocol, network administrators can query the kernel to retrieve information on TCP connections that are being used by the main MPTCP socket. In this example, we&amp;#8217;re running &lt;code&gt;ss&lt;/code&gt; on the client filtering on the server listening port, where information relevant to MPTCP can be read after &lt;code&gt;tcp-ulp-mptcp&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;# ss -nti '( dport :4321 )' dst 192.0.2.1 State Recv-Q Send-Q Local Address:Port Peer Address:PortProcess ESTAB 0 0 192.0.2.2:44176 192.0.2.1:4321 cubic wscale:7,7 [...] bytes_sent:32 bytes_acked:33 [...] tcp-ulp-mptcp flags:Mmec token:0000(id:0)/768f615c(id:0) seq:127af91ad1b321fb sfseq:1 ssnoff:c7304b5f maplen:0 &lt;/pre&gt; &lt;h3&gt;SS command output explained&lt;/h3&gt; &lt;p&gt;The line below &lt;code&gt;tcp-ulp-mptcp&lt;/code&gt; is the output of &lt;code&gt;ss&lt;/code&gt; in the client namespace immediately following the transmission of packet 6 in the previous section:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Each value of &lt;code&gt;token&lt;/code&gt; is the truncated Hashed Message Authentication Code algorithm (HMAC) of the remote peer&amp;#8217;s key, which the client receives during the three-way handshake. Further &lt;code&gt;MP_JOIN SYN&lt;/code&gt; packets will use that value to prove that they have not been spoofed. The &lt;code&gt;id&lt;/code&gt; is the subflow identifier as specified in the RFC. For non-&lt;code&gt;MP_JOIN&lt;/code&gt; sockets, only the local token and ID are available.&lt;/li&gt; &lt;li&gt;&lt;code&gt;flags&lt;/code&gt; is a bitmask containing information on the subflow state. For instance, &lt;code&gt;M/m&lt;/code&gt; records the presence of the &lt;code&gt;MP_CAPABLE&lt;/code&gt; suboption in the three-way handshake. The &lt;code&gt;c&lt;/code&gt; means that the client received the server&amp;#8217;s key (that is, it acknowledged the SYN/ACK), while &lt;code&gt;e&lt;/code&gt; means that the exchange of both MPTCP keys is complete.&lt;/li&gt; &lt;li&gt;&lt;code&gt;seq&lt;/code&gt; denotes the next MPTCP sequence number that the endpoint expects on reception, or, equivalently, the DACK value for the next transmitted packet.&lt;/li&gt; &lt;li&gt;&lt;code&gt;sfseq&lt;/code&gt; is the subflow sequence number, meaning that it is the current TCP ACK value for this subflow.&lt;/li&gt; &lt;li&gt;&lt;code&gt;ssnoff&lt;/code&gt; is the current difference between the TCP sequence number and the MPTCP sequence number for this subflow. If you are using a single subflow, this value will not change during the connection. If you are using more than one subflow to simultaneously carry data segments, then this value can increase or decrease depending on the path capacity.&lt;/li&gt; &lt;li&gt;&lt;code&gt;maplen&lt;/code&gt; indicates how many bytes are left to fill the current DSS map.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Note that we can compute the value of &lt;code&gt;seq&lt;/code&gt; by starting from the server key in the SYN/ACK (which is packet 2 of the capture) and computing the server&amp;#8217;s Initial Data Sequence Number (IDSN), then truncating &lt;code&gt;sha256(ntohll(bb206e3023b47a2d))&lt;/code&gt; to the least-significant 64-bit, as specified by &lt;a target="_blank" rel="nofollow" href="https://tools.ietf.org/html/rfc8684#section-3.3.2"&gt;RFC 8684&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Also note that, because the client is not receiving any data from the server, &lt;code&gt;seq&lt;/code&gt; remains equal to the IDSN  throughout the connection&amp;#8217;s lifetime. For the same reason, the value of &lt;code&gt;sfseq&lt;/code&gt; is constantly equal to 1 in the example. We can see the IDSN in the DSN number of packet 10 and in the DACK number of packets 6 and 8 (in decimal format: &lt;code&gt;1331650533424046587&lt;/code&gt;), as well as in the output of &lt;code&gt;ss&lt;/code&gt; (in hex format: &lt;code&gt;127af91ad1b321fb&lt;/code&gt;). Similarly, in this example the SSN offset (&lt;code&gt;c7304b5f&lt;/code&gt; in the &lt;code&gt;ss&lt;/code&gt; output)  is constantly equal to the initial TCP sequence number (&lt;code&gt;3341831007&lt;/code&gt; in the SYN/ACK, packet 2 of the capture output).&lt;/p&gt; &lt;h2&gt;Conclusion and what&amp;#8217;s next&lt;/h2&gt; &lt;p&gt;In realistic scenarios, MPTCP will generally use more than one subflow. In this way, sockets can preserve connectivity even after an event causes a failure in one of the L4 paths. In the next article, we will show you how to use &lt;code&gt;iproute2&lt;/code&gt; to configure multiple TCP paths on RHEL 8.3, and how to watch &lt;code&gt;ncat&lt;/code&gt; doing multipath for real.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#38;linkname=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F08%2F19%2Fmultipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows%2F&amp;#038;title=Multipath%20TCP%20on%20Red%20Hat%20Enterprise%20Linux%208.3%3A%20From%200%20to%201%20subflows" data-a2a-url="https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/" data-a2a-title="Multipath TCP on Red Hat Enterprise Linux 8.3: From 0 to 1 subflows"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/"&gt;Multipath TCP on Red Hat Enterprise Linux 8.3: From 0 to 1 subflows&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/e_noUn9Fb-Q" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Multipath TCP (MPTCP) extends traditional TCP to allow reliable end-to-end delivery over multiple simultaneous TCP paths, and is coming as a tech preview on Red Hat Enterprise Linux 8.3. This is the first of two articles for users who want to practice with the new MPTCP functionality on a live system. In this first part, we [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/"&gt;Multipath TCP on Red Hat Enterprise Linux 8.3: From 0 to 1 subflows&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">756817</post-id><dc:creator>Davide Caratti</dc:creator><dc:date>2020-08-19T07:00:07Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/08/19/multipath-tcp-on-red-hat-enterprise-linux-8-3-from-0-to-1-subflows/</feedburner:origLink></entry></feed>
